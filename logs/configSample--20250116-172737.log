vocabulary size: 123
n tunes: 400
n train tunes: 368
n validation tunes: 32
min, max length 54 6278
Building the model
  number of parameters: 5582228
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   15129      (32, None, 123)
    InputLayer                       0          (32, None)
    LSTMLayer                        1303552    (32, None, 512)
    DropoutLayer                     0          (32, None, 512)
    LSTMLayer                        2100224    (32, None, 512)
    DropoutLayer                     0          (32, None, 512)
    LSTMLayer                        2100224    (32, None, 512)
    DropoutLayer                     0          (32, None, 512)
    ReshapeLayer                     0          (None, 512)
    DenseLayer                       63099      (None, 123)
Train model
1/2200 (epoch 0.091) train_loss=1116.34399414 time/batch=5.70s
2/2200 (epoch 0.182) train_loss=602.13989258 time/batch=3.73s
3/2200 (epoch 0.273) train_loss=1311.91552734 time/batch=8.25s
4/2200 (epoch 0.364) train_loss=1038.95629883 time/batch=30.85s
5/2200 (epoch 0.455) train_loss=780.90924072 time/batch=12.45s
6/2200 (epoch 0.545) train_loss=615.69537354 time/batch=33.70s
7/2200 (epoch 0.636) train_loss=1302.25671387 time/batch=21.10s
8/2200 (epoch 0.727) train_loss=1087.69775391 time/batch=18.29s
9/2200 (epoch 0.818) train_loss=478.95816040 time/batch=13.84s
10/2200 (epoch 0.909) train_loss=550.49755859 time/batch=23.22s
11/2200 (epoch 1.000) train_loss=892.97973633 time/batch=6.27s
12/2200 (epoch 1.091) train_loss=702.36486816 time/batch=8.04s
13/2200 (epoch 1.182) train_loss=884.57678223 time/batch=37.89s
14/2200 (epoch 1.273) train_loss=949.95861816 time/batch=15.70s
15/2200 (epoch 1.364) train_loss=556.39056396 time/batch=8.65s
16/2200 (epoch 1.455) train_loss=1232.17956543 time/batch=20.21s
17/2200 (epoch 1.545) train_loss=1302.89233398 time/batch=25.70s
18/2200 (epoch 1.636) train_loss=889.81237793 time/batch=10.09s
19/2200 (epoch 1.727) train_loss=462.79083252 time/batch=14.02s
20/2200 (epoch 1.818) train_loss=697.94750977 time/batch=23.59s
21/2200 (epoch 1.909) train_loss=610.47711182 time/batch=15.21s
22/2200 (epoch 2.000) train_loss=480.69229126 time/batch=5.08s
23/2200 (epoch 2.091) train_loss=916.89843750 time/batch=6.75s
24/2200 (epoch 2.182) train_loss=863.94818115 time/batch=16.89s
25/2200 (epoch 2.273) train_loss=535.59533691 time/batch=14.78s
26/2200 (epoch 2.364) train_loss=432.80685425 time/batch=13.97s
27/2200 (epoch 2.455) train_loss=1322.55737305 time/batch=10.63s
28/2200 (epoch 2.545) train_loss=868.74896240 time/batch=6.72s
29/2200 (epoch 2.636) train_loss=1150.42883301 time/batch=8.29s
30/2200 (epoch 2.727) train_loss=807.20520020 time/batch=11.50s
31/2200 (epoch 2.818) train_loss=740.97821045 time/batch=26.23s
32/2200 (epoch 2.909) train_loss=564.75311279 time/batch=4.61s
33/2200 (epoch 3.000) train_loss=572.41516113 time/batch=5.08s
34/2200 (epoch 3.091) train_loss=385.72268677 time/batch=3.21s
35/2200 (epoch 3.182) train_loss=471.39666748 time/batch=15.64s
36/2200 (epoch 3.273) train_loss=536.99383545 time/batch=4.43s
37/2200 (epoch 3.364) train_loss=731.95568848 time/batch=6.09s
38/2200 (epoch 3.455) train_loss=1010.71533203 time/batch=8.45s
39/2200 (epoch 3.545) train_loss=723.72943115 time/batch=26.15s
40/2200 (epoch 3.636) train_loss=885.30926514 time/batch=7.06s
41/2200 (epoch 3.727) train_loss=608.87841797 time/batch=5.13s
42/2200 (epoch 3.818) train_loss=758.11682129 time/batch=18.58s
43/2200 (epoch 3.909) train_loss=1093.90942383 time/batch=9.27s
44/2200 (epoch 4.000) train_loss=1189.13354492 time/batch=10.76s
45/2200 (epoch 4.091) train_loss=842.91778564 time/batch=6.94s
46/2200 (epoch 4.182) train_loss=692.25238037 time/batch=5.57s
47/2200 (epoch 4.273) train_loss=786.03161621 time/batch=18.75s
48/2200 (epoch 4.364) train_loss=405.75314331 time/batch=3.36s
49/2200 (epoch 4.455) train_loss=1170.02172852 time/batch=9.59s
50/2200 (epoch 4.545) train_loss=465.91900635 time/batch=3.70s
51/2200 (epoch 4.636) train_loss=934.05920410 time/batch=7.91s
52/2200 (epoch 4.727) train_loss=547.44207764 time/batch=4.58s
53/2200 (epoch 4.818) train_loss=532.47454834 time/batch=16.48s
54/2200 (epoch 4.909) train_loss=791.99737549 time/batch=25.52s
55/2200 (epoch 5.000) train_loss=1086.80566406 time/batch=9.64s
56/2200 (epoch 5.091) train_loss=801.27636719 time/batch=17.59s
57/2200 (epoch 5.182) train_loss=1204.73950195 time/batch=9.33s
58/2200 (epoch 5.273) train_loss=735.02752686 time/batch=5.65s
59/2200 (epoch 5.364) train_loss=1160.76599121 time/batch=10.07s
60/2200 (epoch 5.455) train_loss=560.47857666 time/batch=3.85s
61/2200 (epoch 5.545) train_loss=864.47613525 time/batch=6.27s
62/2200 (epoch 5.636) train_loss=558.92065430 time/batch=14.80s
63/2200 (epoch 5.727) train_loss=513.90197754 time/batch=4.36s
64/2200 (epoch 5.818) train_loss=897.07269287 time/batch=6.97s
65/2200 (epoch 5.909) train_loss=442.15286255 time/batch=13.79s
66/2200 (epoch 6.000) train_loss=680.64801025 time/batch=23.08s
67/2200 (epoch 6.091) train_loss=1156.80078125 time/batch=8.17s
68/2200 (epoch 6.182) train_loss=450.93499756 time/batch=3.57s
69/2200 (epoch 6.273) train_loss=699.29132080 time/batch=5.33s
70/2200 (epoch 6.364) train_loss=1011.91455078 time/batch=8.98s
71/2200 (epoch 6.455) train_loss=565.30596924 time/batch=4.20s
72/2200 (epoch 6.545) train_loss=580.15081787 time/batch=5.07s
73/2200 (epoch 6.636) train_loss=737.18493652 time/batch=23.76s
74/2200 (epoch 6.727) train_loss=1097.45153809 time/batch=10.22s
75/2200 (epoch 6.818) train_loss=518.24108887 time/batch=15.57s
76/2200 (epoch 6.909) train_loss=844.16357422 time/batch=6.60s
77/2200 (epoch 7.000) train_loss=1020.30554199 time/batch=18.03s
78/2200 (epoch 7.091) train_loss=734.88671875 time/batch=23.41s
79/2200 (epoch 7.182) train_loss=569.37915039 time/batch=4.28s
80/2200 (epoch 7.273) train_loss=375.04959106 time/batch=2.88s
81/2200 (epoch 7.364) train_loss=796.48931885 time/batch=17.32s
82/2200 (epoch 7.455) train_loss=1260.88757324 time/batch=10.15s
83/2200 (epoch 7.545) train_loss=520.38781738 time/batch=15.63s
84/2200 (epoch 7.636) train_loss=1153.08483887 time/batch=10.80s
85/2200 (epoch 7.727) train_loss=497.62490845 time/batch=3.88s
86/2200 (epoch 7.818) train_loss=876.73419189 time/batch=6.82s
87/2200 (epoch 7.909) train_loss=667.96295166 time/batch=6.04s
88/2200 (epoch 8.000) train_loss=894.10290527 time/batch=10.38s
89/2200 (epoch 8.091) train_loss=461.67440796 time/batch=14.53s
90/2200 (epoch 8.182) train_loss=796.75152588 time/batch=18.27s
91/2200 (epoch 8.273) train_loss=568.00585938 time/batch=16.40s
92/2200 (epoch 8.364) train_loss=1293.01672363 time/batch=12.53s
93/2200 (epoch 8.455) train_loss=975.84692383 time/batch=7.89s
94/2200 (epoch 8.545) train_loss=483.48336792 time/batch=4.13s
95/2200 (epoch 8.636) train_loss=688.10034180 time/batch=5.99s
96/2200 (epoch 8.727) train_loss=899.17962646 time/batch=8.62s
97/2200 (epoch 8.818) train_loss=609.50762939 time/batch=6.27s
98/2200 (epoch 8.909) train_loss=1032.59570312 time/batch=9.29s
99/2200 (epoch 9.000) train_loss=520.51428223 time/batch=9.64s
100/2200 (epoch 9.091) train_loss=1281.59521484 time/batch=12.60s
101/2200 (epoch 9.182) train_loss=985.07720947 time/batch=8.63s
102/2200 (epoch 9.273) train_loss=856.72418213 time/batch=18.83s
103/2200 (epoch 9.364) train_loss=769.15606689 time/batch=6.47s
104/2200 (epoch 9.455) train_loss=415.06985474 time/batch=3.24s
105/2200 (epoch 9.545) train_loss=618.56433105 time/batch=5.05s
106/2200 (epoch 9.636) train_loss=435.21249390 time/batch=3.58s
107/2200 (epoch 9.727) train_loss=946.80187988 time/batch=8.90s
108/2200 (epoch 9.818) train_loss=478.70278931 time/batch=15.99s
109/2200 (epoch 9.909) train_loss=773.51855469 time/batch=9.11s
110/2200 (epoch 10.000) train_loss=673.77862549 time/batch=8.97s
  saved to metadata/configSample--20250116-172737.pkl
111/2200 (epoch 10.091) train_loss=540.76110840 time/batch=4.04s
112/2200 (epoch 10.182) train_loss=1189.40124512 time/batch=9.37s
113/2200 (epoch 10.273) train_loss=752.58428955 time/batch=23.74s
114/2200 (epoch 10.364) train_loss=653.17956543 time/batch=4.87s
115/2200 (epoch 10.455) train_loss=861.54144287 time/batch=6.26s
116/2200 (epoch 10.545) train_loss=521.43798828 time/batch=15.08s
117/2200 (epoch 10.636) train_loss=644.62023926 time/batch=5.13s
118/2200 (epoch 10.727) train_loss=858.20935059 time/batch=17.05s
119/2200 (epoch 10.818) train_loss=1066.73925781 time/batch=9.79s
120/2200 (epoch 10.909) train_loss=389.91171265 time/batch=3.09s
121/2200 (epoch 11.000) train_loss=869.19757080 time/batch=10.35s
122/2200 (epoch 11.091) train_loss=537.53942871 time/batch=4.01s
123/2200 (epoch 11.182) train_loss=867.72625732 time/batch=6.86s
124/2200 (epoch 11.273) train_loss=1283.82006836 time/batch=12.72s
125/2200 (epoch 11.364) train_loss=1140.59741211 time/batch=9.27s
126/2200 (epoch 11.455) train_loss=454.32275391 time/batch=3.26s
127/2200 (epoch 11.545) train_loss=690.96588135 time/batch=5.72s
128/2200 (epoch 11.636) train_loss=418.18475342 time/batch=3.52s
129/2200 (epoch 11.727) train_loss=810.69396973 time/batch=19.26s
130/2200 (epoch 11.818) train_loss=560.41491699 time/batch=5.01s
131/2200 (epoch 11.909) train_loss=751.76678467 time/batch=26.32s
132/2200 (epoch 12.000) train_loss=902.72271729 time/batch=7.11s
133/2200 (epoch 12.091) train_loss=724.73962402 time/batch=5.43s
134/2200 (epoch 12.182) train_loss=438.89196777 time/batch=3.20s
135/2200 (epoch 12.273) train_loss=745.24438477 time/batch=17.24s
136/2200 (epoch 12.364) train_loss=869.55596924 time/batch=6.54s
137/2200 (epoch 12.455) train_loss=813.62780762 time/batch=6.81s
138/2200 (epoch 12.545) train_loss=400.24008179 time/batch=3.35s
139/2200 (epoch 12.636) train_loss=405.87216187 time/batch=14.50s
140/2200 (epoch 12.727) train_loss=1303.68103027 time/batch=11.40s
141/2200 (epoch 12.818) train_loss=543.19946289 time/batch=4.07s
142/2200 (epoch 12.909) train_loss=1129.02282715 time/batch=8.58s
143/2200 (epoch 13.000) train_loss=801.46649170 time/batch=9.44s
144/2200 (epoch 13.091) train_loss=838.52990723 time/batch=18.08s
145/2200 (epoch 13.182) train_loss=1276.79528809 time/batch=13.43s
146/2200 (epoch 13.273) train_loss=909.15246582 time/batch=7.84s
147/2200 (epoch 13.364) train_loss=407.91882324 time/batch=3.19s
148/2200 (epoch 13.455) train_loss=612.54565430 time/batch=4.91s
149/2200 (epoch 13.545) train_loss=719.61065674 time/batch=6.33s
150/2200 (epoch 13.636) train_loss=539.61730957 time/batch=15.67s
151/2200 (epoch 13.727) train_loss=1149.23767090 time/batch=9.21s
152/2200 (epoch 13.818) train_loss=849.45782471 time/batch=7.72s
153/2200 (epoch 13.909) train_loss=771.04821777 time/batch=25.66s
154/2200 (epoch 14.000) train_loss=525.64300537 time/batch=4.16s
155/2200 (epoch 14.091) train_loss=875.57507324 time/batch=6.91s
156/2200 (epoch 14.182) train_loss=1146.14709473 time/batch=9.01s
157/2200 (epoch 14.273) train_loss=420.76184082 time/batch=15.18s
158/2200 (epoch 14.364) train_loss=851.55737305 time/batch=18.17s
159/2200 (epoch 14.455) train_loss=662.76239014 time/batch=5.94s
160/2200 (epoch 14.545) train_loss=703.13806152 time/batch=27.65s
161/2200 (epoch 14.636) train_loss=454.97814941 time/batch=4.20s
162/2200 (epoch 14.727) train_loss=541.67114258 time/batch=17.23s
163/2200 (epoch 14.818) train_loss=832.55725098 time/batch=7.91s
164/2200 (epoch 14.909) train_loss=728.72229004 time/batch=8.73s
165/2200 (epoch 15.000) train_loss=1265.89489746 time/batch=13.82s
166/2200 (epoch 15.091) train_loss=724.02026367 time/batch=6.34s
167/2200 (epoch 15.182) train_loss=531.72857666 time/batch=4.46s
168/2200 (epoch 15.273) train_loss=1055.84558105 time/batch=9.32s
169/2200 (epoch 15.364) train_loss=1269.78552246 time/batch=13.93s
170/2200 (epoch 15.455) train_loss=835.85333252 time/batch=7.03s
171/2200 (epoch 15.545) train_loss=445.99060059 time/batch=3.69s
172/2200 (epoch 15.636) train_loss=439.08447266 time/batch=16.23s
173/2200 (epoch 15.727) train_loss=750.30902100 time/batch=19.26s
174/2200 (epoch 15.818) train_loss=604.18304443 time/batch=17.84s
175/2200 (epoch 15.909) train_loss=1015.22186279 time/batch=10.36s
176/2200 (epoch 16.000) train_loss=691.88214111 time/batch=27.70s
177/2200 (epoch 16.091) train_loss=541.67883301 time/batch=4.75s
178/2200 (epoch 16.182) train_loss=925.59735107 time/batch=8.25s
179/2200 (epoch 16.273) train_loss=1208.54150391 time/batch=10.79s
180/2200 (epoch 16.364) train_loss=450.57095337 time/batch=3.96s
181/2200 (epoch 16.455) train_loss=441.84762573 time/batch=16.81s
182/2200 (epoch 16.545) train_loss=685.38269043 time/batch=5.66s
183/2200 (epoch 16.636) train_loss=699.29089355 time/batch=27.20s
184/2200 (epoch 16.727) train_loss=921.74127197 time/batch=8.62s
185/2200 (epoch 16.818) train_loss=757.05926514 time/batch=19.51s
186/2200 (epoch 16.909) train_loss=588.54119873 time/batch=16.77s
187/2200 (epoch 17.000) train_loss=899.01348877 time/batch=9.77s
188/2200 (epoch 17.091) train_loss=688.63861084 time/batch=5.66s
189/2200 (epoch 17.182) train_loss=574.26611328 time/batch=5.01s
190/2200 (epoch 17.273) train_loss=1158.39184570 time/batch=10.15s
191/2200 (epoch 17.364) train_loss=902.58166504 time/batch=8.35s
192/2200 (epoch 17.455) train_loss=1265.21032715 time/batch=12.75s
193/2200 (epoch 17.545) train_loss=466.50469971 time/batch=4.24s
194/2200 (epoch 17.636) train_loss=855.33355713 time/batch=19.92s
195/2200 (epoch 17.727) train_loss=4752.84082031 time/batch=7.75s
196/2200 (epoch 17.818) train_loss=384.54861450 time/batch=3.39s
197/2200 (epoch 17.909) train_loss=692.35711670 time/batch=27.19s
198/2200 (epoch 18.000) train_loss=625.78613281 time/batch=8.40s
199/2200 (epoch 18.091) train_loss=562.44458008 time/batch=4.84s
200/2200 (epoch 18.182) train_loss=720.22717285 time/batch=26.60s
201/2200 (epoch 18.273) train_loss=893.43347168 time/batch=7.49s
202/2200 (epoch 18.364) train_loss=695.17590332 time/batch=5.59s
203/2200 (epoch 18.455) train_loss=748.05334473 time/batch=19.21s
204/2200 (epoch 18.545) train_loss=1140.23352051 time/batch=10.15s
205/2200 (epoch 18.636) train_loss=877.05926514 time/batch=7.91s
206/2200 (epoch 18.727) train_loss=1128.84570312 time/batch=11.37s
207/2200 (epoch 18.818) train_loss=474.01620483 time/batch=4.07s
208/2200 (epoch 18.909) train_loss=844.76708984 time/batch=13.47s
209/2200 (epoch 19.000) train_loss=472.44094849 time/batch=18.15s
210/2200 (epoch 19.091) train_loss=459.55187988 time/batch=16.29s
211/2200 (epoch 19.182) train_loss=1196.85937500 time/batch=9.30s
212/2200 (epoch 19.273) train_loss=695.55603027 time/batch=5.71s
213/2200 (epoch 19.364) train_loss=939.94262695 time/batch=8.23s
214/2200 (epoch 19.455) train_loss=1206.17626953 time/batch=13.51s
215/2200 (epoch 19.545) train_loss=854.32891846 time/batch=19.32s
216/2200 (epoch 19.636) train_loss=566.02307129 time/batch=17.21s
217/2200 (epoch 19.727) train_loss=827.40838623 time/batch=7.61s
218/2200 (epoch 19.818) train_loss=610.89807129 time/batch=5.26s
219/2200 (epoch 19.909) train_loss=500.57754517 time/batch=4.48s
220/2200 (epoch 20.000) train_loss=395.13302612 time/batch=3.60s
  saved to metadata/configSample--20250116-172737.pkl
221/2200 (epoch 20.091) train_loss=519.30969238 time/batch=17.23s
222/2200 (epoch 20.182) train_loss=897.42724609 time/batch=7.50s
223/2200 (epoch 20.273) train_loss=472.72665405 time/batch=3.98s
224/2200 (epoch 20.364) train_loss=1149.90051270 time/batch=9.88s
225/2200 (epoch 20.455) train_loss=662.57519531 time/batch=5.95s
226/2200 (epoch 20.545) train_loss=670.73205566 time/batch=6.37s
227/2200 (epoch 20.636) train_loss=1107.63891602 time/batch=10.32s
228/2200 (epoch 20.727) train_loss=1095.83093262 time/batch=13.19s
229/2200 (epoch 20.818) train_loss=381.01254272 time/batch=3.28s
230/2200 (epoch 20.909) train_loss=799.48150635 time/batch=18.86s
231/2200 (epoch 21.000) train_loss=519.25561523 time/batch=16.33s
232/2200 (epoch 21.091) train_loss=1252.13452148 time/batch=11.91s
233/2200 (epoch 21.182) train_loss=383.01776123 time/batch=3.39s
234/2200 (epoch 21.273) train_loss=543.94427490 time/batch=4.51s
235/2200 (epoch 21.364) train_loss=1072.59411621 time/batch=9.33s
236/2200 (epoch 21.455) train_loss=1029.75646973 time/batch=12.61s
237/2200 (epoch 21.545) train_loss=741.19714355 time/batch=26.58s
238/2200 (epoch 21.636) train_loss=444.76501465 time/batch=4.09s
239/2200 (epoch 21.727) train_loss=653.14227295 time/batch=6.16s
240/2200 (epoch 21.818) train_loss=780.93939209 time/batch=19.66s
241/2200 (epoch 21.909) train_loss=856.91912842 time/batch=7.52s
242/2200 (epoch 22.000) train_loss=684.92694092 time/batch=6.34s
setting learning rate to 0.0029100
243/2200 (epoch 22.091) train_loss=784.91839600 time/batch=19.35s
244/2200 (epoch 22.182) train_loss=553.16571045 time/batch=5.08s
245/2200 (epoch 22.273) train_loss=977.69299316 time/batch=8.72s
246/2200 (epoch 22.364) train_loss=1276.25012207 time/batch=13.57s
247/2200 (epoch 22.455) train_loss=449.86740112 time/batch=16.13s
248/2200 (epoch 22.545) train_loss=840.77917480 time/batch=7.45s
249/2200 (epoch 22.636) train_loss=1078.31713867 time/batch=10.09s
250/2200 (epoch 22.727) train_loss=702.72979736 time/batch=26.75s
251/2200 (epoch 22.818) train_loss=517.54370117 time/batch=17.38s
252/2200 (epoch 22.909) train_loss=756.06774902 time/batch=7.00s
253/2200 (epoch 23.000) train_loss=590.72784424 time/batch=5.53s
setting learning rate to 0.0028227
254/2200 (epoch 23.091) train_loss=559.79138184 time/batch=17.42s
255/2200 (epoch 23.182) train_loss=1068.33325195 time/batch=9.74s
256/2200 (epoch 23.273) train_loss=684.82690430 time/batch=6.41s
257/2200 (epoch 23.364) train_loss=1276.92456055 time/batch=13.90s
258/2200 (epoch 23.455) train_loss=756.18774414 time/batch=27.65s
259/2200 (epoch 23.545) train_loss=819.41284180 time/batch=18.82s
260/2200 (epoch 23.636) train_loss=1001.67694092 time/batch=9.78s
261/2200 (epoch 23.727) train_loss=713.13006592 time/batch=6.35s
262/2200 (epoch 23.818) train_loss=385.82061768 time/batch=3.28s
263/2200 (epoch 23.909) train_loss=437.11865234 time/batch=3.84s
264/2200 (epoch 24.000) train_loss=608.62841797 time/batch=6.83s
setting learning rate to 0.0027380
265/2200 (epoch 24.091) train_loss=552.99047852 time/batch=5.25s
266/2200 (epoch 24.182) train_loss=457.60018921 time/batch=3.61s
267/2200 (epoch 24.273) train_loss=652.64147949 time/batch=5.42s
268/2200 (epoch 24.364) train_loss=822.62786865 time/batch=7.44s
269/2200 (epoch 24.455) train_loss=910.34014893 time/batch=7.82s
270/2200 (epoch 24.545) train_loss=1019.65625000 time/batch=9.55s
271/2200 (epoch 24.636) train_loss=1280.20776367 time/batch=13.76s
272/2200 (epoch 24.727) train_loss=602.95391846 time/batch=6.24s
273/2200 (epoch 24.818) train_loss=699.11193848 time/batch=20.19s
274/2200 (epoch 24.909) train_loss=435.28579712 time/batch=16.52s
275/2200 (epoch 25.000) train_loss=708.31640625 time/batch=27.72s
setting learning rate to 0.0026559
276/2200 (epoch 25.091) train_loss=1146.06127930 time/batch=9.84s
277/2200 (epoch 25.182) train_loss=723.72076416 time/batch=28.45s
278/2200 (epoch 25.273) train_loss=731.86560059 time/batch=6.11s
279/2200 (epoch 25.364) train_loss=517.23382568 time/batch=17.33s
280/2200 (epoch 25.455) train_loss=1290.14111328 time/batch=13.12s
281/2200 (epoch 25.545) train_loss=885.39007568 time/batch=8.11s
282/2200 (epoch 25.636) train_loss=653.57495117 time/batch=5.50s
283/2200 (epoch 25.727) train_loss=903.82312012 time/batch=9.03s
284/2200 (epoch 25.818) train_loss=741.37811279 time/batch=18.91s
285/2200 (epoch 25.909) train_loss=546.73992920 time/batch=6.24s
286/2200 (epoch 26.000) train_loss=404.62850952 time/batch=3.59s
setting learning rate to 0.0025762
287/2200 (epoch 26.091) train_loss=1049.57531738 time/batch=8.88s
288/2200 (epoch 26.182) train_loss=399.22399902 time/batch=3.66s
289/2200 (epoch 26.273) train_loss=449.95916748 time/batch=16.62s
290/2200 (epoch 26.364) train_loss=863.76385498 time/batch=19.90s
291/2200 (epoch 26.455) train_loss=1285.55017090 time/batch=13.60s
292/2200 (epoch 26.545) train_loss=708.36578369 time/batch=25.65s
293/2200 (epoch 26.636) train_loss=1032.12500000 time/batch=10.17s
294/2200 (epoch 26.727) train_loss=698.93554688 time/batch=5.88s
295/2200 (epoch 26.818) train_loss=550.40771484 time/batch=4.90s
296/2200 (epoch 26.909) train_loss=586.44854736 time/batch=5.52s
297/2200 (epoch 27.000) train_loss=708.50109863 time/batch=17.52s
setting learning rate to 0.0024989
298/2200 (epoch 27.091) train_loss=1167.86718750 time/batch=10.00s
299/2200 (epoch 27.182) train_loss=537.88732910 time/batch=17.02s
300/2200 (epoch 27.273) train_loss=864.75610352 time/batch=7.89s
301/2200 (epoch 27.364) train_loss=532.85455322 time/batch=4.51s
302/2200 (epoch 27.455) train_loss=552.50750732 time/batch=5.25s
303/2200 (epoch 27.545) train_loss=485.74044800 time/batch=5.86s
304/2200 (epoch 27.636) train_loss=1093.35815430 time/batch=10.62s
305/2200 (epoch 27.727) train_loss=427.58840942 time/batch=16.58s
306/2200 (epoch 27.818) train_loss=913.37438965 time/batch=11.29s
307/2200 (epoch 27.909) train_loss=617.43139648 time/batch=6.44s
308/2200 (epoch 28.000) train_loss=968.14831543 time/batch=27.43s
setting learning rate to 0.0024239
309/2200 (epoch 28.091) train_loss=435.71481323 time/batch=15.98s
310/2200 (epoch 28.182) train_loss=1139.15991211 time/batch=10.00s
311/2200 (epoch 28.273) train_loss=359.25433350 time/batch=3.52s
312/2200 (epoch 28.364) train_loss=719.47656250 time/batch=6.48s
313/2200 (epoch 28.455) train_loss=1282.06628418 time/batch=13.35s
314/2200 (epoch 28.545) train_loss=876.65332031 time/batch=7.84s
315/2200 (epoch 28.636) train_loss=900.42785645 time/batch=9.67s
316/2200 (epoch 28.727) train_loss=808.41119385 time/batch=18.80s
317/2200 (epoch 28.818) train_loss=527.09344482 time/batch=18.44s
318/2200 (epoch 28.909) train_loss=607.38110352 time/batch=5.65s
319/2200 (epoch 29.000) train_loss=785.00183105 time/batch=28.67s
setting learning rate to 0.0023512
320/2200 (epoch 29.091) train_loss=440.52792358 time/batch=3.75s
321/2200 (epoch 29.182) train_loss=1241.08105469 time/batch=11.53s
322/2200 (epoch 29.273) train_loss=377.82214355 time/batch=3.30s
323/2200 (epoch 29.364) train_loss=870.41918945 time/batch=7.30s
324/2200 (epoch 29.455) train_loss=577.23156738 time/batch=5.11s
325/2200 (epoch 29.545) train_loss=695.07049561 time/batch=26.27s
326/2200 (epoch 29.636) train_loss=1211.66052246 time/batch=13.93s
327/2200 (epoch 29.727) train_loss=542.15197754 time/batch=5.48s
328/2200 (epoch 29.818) train_loss=692.65899658 time/batch=6.32s
329/2200 (epoch 29.909) train_loss=935.43841553 time/batch=19.90s
330/2200 (epoch 30.000) train_loss=855.37762451 time/batch=7.95s
setting learning rate to 0.0022807
  saved to metadata/configSample--20250116-172737.pkl
331/2200 (epoch 30.091) train_loss=396.68829346 time/batch=3.50s
332/2200 (epoch 30.182) train_loss=603.91558838 time/batch=5.12s
333/2200 (epoch 30.273) train_loss=821.29156494 time/batch=7.10s
334/2200 (epoch 30.364) train_loss=601.21038818 time/batch=6.03s
335/2200 (epoch 30.455) train_loss=548.39916992 time/batch=17.36s
336/2200 (epoch 30.545) train_loss=439.04220581 time/batch=15.96s
337/2200 (epoch 30.636) train_loss=926.38885498 time/batch=8.11s
338/2200 (epoch 30.727) train_loss=760.44061279 time/batch=26.43s
339/2200 (epoch 30.818) train_loss=1247.67468262 time/batch=10.54s
340/2200 (epoch 30.909) train_loss=1178.06433105 time/batch=11.44s
341/2200 (epoch 31.000) train_loss=930.01373291 time/batch=19.20s
setting learning rate to 0.0022123
342/2200 (epoch 31.091) train_loss=556.60797119 time/batch=4.60s
343/2200 (epoch 31.182) train_loss=1213.99572754 time/batch=10.89s
344/2200 (epoch 31.273) train_loss=544.14538574 time/batch=17.26s
345/2200 (epoch 31.364) train_loss=745.09820557 time/batch=26.05s
346/2200 (epoch 31.455) train_loss=685.01031494 time/batch=6.17s
347/2200 (epoch 31.545) train_loss=616.18304443 time/batch=6.36s
348/2200 (epoch 31.636) train_loss=376.32434082 time/batch=3.50s
349/2200 (epoch 31.727) train_loss=904.60626221 time/batch=7.84s
350/2200 (epoch 31.818) train_loss=1114.19860840 time/batch=11.16s
351/2200 (epoch 31.909) train_loss=649.01165771 time/batch=19.43s
352/2200 (epoch 32.000) train_loss=985.54461670 time/batch=13.70s
setting learning rate to 0.0021459
353/2200 (epoch 32.091) train_loss=1277.74560547 time/batch=13.70s
354/2200 (epoch 32.182) train_loss=561.15985107 time/batch=16.85s
355/2200 (epoch 32.273) train_loss=932.84429932 time/batch=8.12s
356/2200 (epoch 32.364) train_loss=437.63211060 time/batch=15.70s
357/2200 (epoch 32.455) train_loss=1136.73486328 time/batch=10.03s
358/2200 (epoch 32.545) train_loss=849.74365234 time/batch=19.15s
359/2200 (epoch 32.636) train_loss=679.78802490 time/batch=5.60s
360/2200 (epoch 32.727) train_loss=756.25213623 time/batch=7.20s
361/2200 (epoch 32.818) train_loss=701.24481201 time/batch=7.49s
362/2200 (epoch 32.909) train_loss=501.56173706 time/batch=4.65s
363/2200 (epoch 33.000) train_loss=678.56103516 time/batch=28.15s
setting learning rate to 0.0020815
364/2200 (epoch 33.091) train_loss=415.18899536 time/batch=3.71s
365/2200 (epoch 33.182) train_loss=603.61315918 time/batch=5.17s
366/2200 (epoch 33.273) train_loss=524.83734131 time/batch=4.19s
367/2200 (epoch 33.364) train_loss=1304.99011230 time/batch=14.10s
368/2200 (epoch 33.455) train_loss=874.31109619 time/batch=7.96s
369/2200 (epoch 33.545) train_loss=993.02447510 time/batch=9.09s
370/2200 (epoch 33.636) train_loss=425.24450684 time/batch=3.96s
371/2200 (epoch 33.727) train_loss=842.99951172 time/batch=19.51s
372/2200 (epoch 33.818) train_loss=727.26788330 time/batch=26.52s
373/2200 (epoch 33.909) train_loss=768.14617920 time/batch=7.89s
374/2200 (epoch 34.000) train_loss=973.44897461 time/batch=9.49s
setting learning rate to 0.0020191
375/2200 (epoch 34.091) train_loss=451.81555176 time/batch=16.83s
376/2200 (epoch 34.182) train_loss=834.68072510 time/batch=18.95s
377/2200 (epoch 34.273) train_loss=768.93640137 time/batch=6.90s
378/2200 (epoch 34.364) train_loss=669.24389648 time/batch=29.90s
379/2200 (epoch 34.455) train_loss=675.76318359 time/batch=5.50s
380/2200 (epoch 34.545) train_loss=802.67059326 time/batch=7.79s
381/2200 (epoch 34.636) train_loss=530.09826660 time/batch=4.52s
382/2200 (epoch 34.727) train_loss=507.39471436 time/batch=16.77s
383/2200 (epoch 34.818) train_loss=987.26330566 time/batch=8.76s
384/2200 (epoch 34.909) train_loss=1284.88842773 time/batch=13.15s
385/2200 (epoch 35.000) train_loss=984.45544434 time/batch=10.16s
setting learning rate to 0.0019585
386/2200 (epoch 35.091) train_loss=1175.91882324 time/batch=10.23s
387/2200 (epoch 35.182) train_loss=794.31970215 time/batch=7.21s
388/2200 (epoch 35.273) train_loss=444.53491211 time/batch=16.80s
389/2200 (epoch 35.364) train_loss=1103.81457520 time/batch=11.34s
390/2200 (epoch 35.455) train_loss=411.20046997 time/batch=3.42s
391/2200 (epoch 35.545) train_loss=728.26055908 time/batch=26.78s
392/2200 (epoch 35.636) train_loss=905.10479736 time/batch=7.58s
393/2200 (epoch 35.727) train_loss=545.82153320 time/batch=4.69s
394/2200 (epoch 35.818) train_loss=675.53509521 time/batch=5.72s
395/2200 (epoch 35.909) train_loss=1033.00073242 time/batch=19.14s
396/2200 (epoch 36.000) train_loss=558.51623535 time/batch=17.07s
setting learning rate to 0.0018998
397/2200 (epoch 36.091) train_loss=1181.81738281 time/batch=10.86s
398/2200 (epoch 36.182) train_loss=739.97930908 time/batch=27.52s
399/2200 (epoch 36.273) train_loss=883.90887451 time/batch=7.25s
400/2200 (epoch 36.364) train_loss=777.59460449 time/batch=20.14s
401/2200 (epoch 36.455) train_loss=851.14239502 time/batch=8.41s
402/2200 (epoch 36.545) train_loss=514.80938721 time/batch=17.65s
403/2200 (epoch 36.636) train_loss=1177.18151855 time/batch=11.71s
404/2200 (epoch 36.727) train_loss=376.82958984 time/batch=3.41s
405/2200 (epoch 36.818) train_loss=570.20666504 time/batch=5.01s
406/2200 (epoch 36.909) train_loss=841.16290283 time/batch=13.41s
407/2200 (epoch 37.000) train_loss=501.58230591 time/batch=4.55s
setting learning rate to 0.0018428
408/2200 (epoch 37.091) train_loss=444.21066284 time/batch=4.12s
409/2200 (epoch 37.182) train_loss=558.43493652 time/batch=4.87s
410/2200 (epoch 37.273) train_loss=542.90106201 time/batch=18.76s
411/2200 (epoch 37.364) train_loss=825.26959229 time/batch=20.15s
412/2200 (epoch 37.455) train_loss=1321.02551270 time/batch=13.65s
413/2200 (epoch 37.545) train_loss=989.32556152 time/batch=8.79s
414/2200 (epoch 37.636) train_loss=800.10888672 time/batch=7.89s
415/2200 (epoch 37.727) train_loss=696.87402344 time/batch=7.73s
416/2200 (epoch 37.818) train_loss=1070.07458496 time/batch=10.25s
417/2200 (epoch 37.909) train_loss=386.80593872 time/batch=3.46s
418/2200 (epoch 38.000) train_loss=740.25390625 time/batch=27.80s
setting learning rate to 0.0017875
419/2200 (epoch 38.091) train_loss=537.28283691 time/batch=4.84s
420/2200 (epoch 38.182) train_loss=708.64447021 time/batch=26.68s
421/2200 (epoch 38.273) train_loss=785.46905518 time/batch=19.16s
422/2200 (epoch 38.364) train_loss=1056.63403320 time/batch=9.63s
423/2200 (epoch 38.455) train_loss=586.75311279 time/batch=18.65s
424/2200 (epoch 38.545) train_loss=1288.75891113 time/batch=14.50s
425/2200 (epoch 38.636) train_loss=895.46868896 time/batch=8.35s
426/2200 (epoch 38.727) train_loss=740.49670410 time/batch=7.06s
427/2200 (epoch 38.818) train_loss=440.23754883 time/batch=4.19s
428/2200 (epoch 38.909) train_loss=451.49652100 time/batch=5.20s
429/2200 (epoch 39.000) train_loss=908.98443604 time/batch=10.28s
setting learning rate to 0.0017339
430/2200 (epoch 39.091) train_loss=1247.58459473 time/batch=13.51s
431/2200 (epoch 39.182) train_loss=821.95819092 time/batch=19.66s
432/2200 (epoch 39.273) train_loss=368.90142822 time/batch=3.45s
433/2200 (epoch 39.364) train_loss=1104.10583496 time/batch=10.00s
434/2200 (epoch 39.455) train_loss=608.69549561 time/batch=5.56s
435/2200 (epoch 39.545) train_loss=516.60827637 time/batch=17.57s
436/2200 (epoch 39.636) train_loss=615.18371582 time/batch=6.25s
437/2200 (epoch 39.727) train_loss=433.45672607 time/batch=16.01s
438/2200 (epoch 39.818) train_loss=877.47937012 time/batch=7.82s
439/2200 (epoch 39.909) train_loss=848.50115967 time/batch=8.81s
440/2200 (epoch 40.000) train_loss=449.36947632 time/batch=4.52s
setting learning rate to 0.0016818
  saved to metadata/configSample--20250116-172737.pkl
441/2200 (epoch 40.091) train_loss=673.43841553 time/batch=6.22s
442/2200 (epoch 40.182) train_loss=1148.33630371 time/batch=10.98s
443/2200 (epoch 40.273) train_loss=1026.33703613 time/batch=9.91s
444/2200 (epoch 40.364) train_loss=1101.90295410 time/batch=12.86s
445/2200 (epoch 40.455) train_loss=834.52246094 time/batch=7.84s
446/2200 (epoch 40.545) train_loss=564.95428467 time/batch=5.23s
447/2200 (epoch 40.636) train_loss=693.32214355 time/batch=26.56s
448/2200 (epoch 40.727) train_loss=505.01168823 time/batch=4.57s
449/2200 (epoch 40.818) train_loss=551.55792236 time/batch=17.51s
450/2200 (epoch 40.909) train_loss=359.12777710 time/batch=3.38s
451/2200 (epoch 41.000) train_loss=799.83374023 time/batch=19.01s
setting learning rate to 0.0016314
452/2200 (epoch 41.091) train_loss=680.02136230 time/batch=6.26s
453/2200 (epoch 41.182) train_loss=842.38134766 time/batch=7.84s
454/2200 (epoch 41.273) train_loss=744.97290039 time/batch=19.04s
455/2200 (epoch 41.364) train_loss=1245.67492676 time/batch=13.53s
456/2200 (epoch 41.455) train_loss=685.36492920 time/batch=27.19s
457/2200 (epoch 41.545) train_loss=1089.71228027 time/batch=10.07s
458/2200 (epoch 41.636) train_loss=906.83538818 time/batch=9.82s
459/2200 (epoch 41.727) train_loss=514.94342041 time/batch=4.43s
460/2200 (epoch 41.818) train_loss=518.65527344 time/batch=17.84s
461/2200 (epoch 41.909) train_loss=528.20697021 time/batch=6.49s
462/2200 (epoch 42.000) train_loss=487.86798096 time/batch=6.22s
setting learning rate to 0.0015824
463/2200 (epoch 42.091) train_loss=1008.00634766 time/batch=9.65s
464/2200 (epoch 42.182) train_loss=593.65759277 time/batch=5.39s
465/2200 (epoch 42.273) train_loss=1252.37426758 time/batch=13.25s
466/2200 (epoch 42.364) train_loss=766.58581543 time/batch=19.43s
467/2200 (epoch 42.455) train_loss=418.88027954 time/batch=16.11s
468/2200 (epoch 42.545) train_loss=366.73410034 time/batch=3.41s
469/2200 (epoch 42.636) train_loss=745.86535645 time/batch=6.43s
470/2200 (epoch 42.727) train_loss=510.22027588 time/batch=17.13s
471/2200 (epoch 42.818) train_loss=883.86865234 time/batch=9.31s
472/2200 (epoch 42.909) train_loss=931.73388672 time/batch=10.63s
473/2200 (epoch 43.000) train_loss=714.13848877 time/batch=28.59s
setting learning rate to 0.0015350
474/2200 (epoch 43.091) train_loss=1016.80987549 time/batch=9.43s
475/2200 (epoch 43.182) train_loss=886.40545654 time/batch=8.53s
476/2200 (epoch 43.273) train_loss=1154.70483398 time/batch=10.64s
477/2200 (epoch 43.364) train_loss=778.76531982 time/batch=19.04s
478/2200 (epoch 43.455) train_loss=522.70379639 time/batch=18.24s
479/2200 (epoch 43.545) train_loss=411.72631836 time/batch=16.53s
480/2200 (epoch 43.636) train_loss=587.98376465 time/batch=27.23s
481/2200 (epoch 43.727) train_loss=523.45483398 time/batch=4.53s
482/2200 (epoch 43.818) train_loss=1055.18273926 time/batch=13.00s
483/2200 (epoch 43.909) train_loss=598.59863281 time/batch=5.45s
484/2200 (epoch 44.000) train_loss=699.42767334 time/batch=6.58s
setting learning rate to 0.0014889
485/2200 (epoch 44.091) train_loss=891.18695068 time/batch=8.07s
486/2200 (epoch 44.182) train_loss=629.78192139 time/batch=5.93s
487/2200 (epoch 44.273) train_loss=972.91595459 time/batch=9.28s
488/2200 (epoch 44.364) train_loss=516.75762939 time/batch=4.91s
489/2200 (epoch 44.455) train_loss=400.40838623 time/batch=15.67s
490/2200 (epoch 44.545) train_loss=898.01629639 time/batch=10.32s
491/2200 (epoch 44.636) train_loss=902.21643066 time/batch=20.27s
492/2200 (epoch 44.727) train_loss=371.87442017 time/batch=3.59s
493/2200 (epoch 44.818) train_loss=498.65380859 time/batch=17.01s
494/2200 (epoch 44.909) train_loss=842.30816650 time/batch=10.88s
495/2200 (epoch 45.000) train_loss=841.58044434 time/batch=27.30s
setting learning rate to 0.0014443
496/2200 (epoch 45.091) train_loss=652.46252441 time/batch=5.74s
497/2200 (epoch 45.182) train_loss=886.27893066 time/batch=7.73s
498/2200 (epoch 45.273) train_loss=433.68359375 time/batch=3.81s
499/2200 (epoch 45.364) train_loss=512.62127686 time/batch=4.67s
Validating
    loss:	1521.992554

500/2200 (epoch 45.455) train_loss=1243.60180664 time/batch=85.28s
501/2200 (epoch 45.545) train_loss=550.22985840 time/batch=5.87s
502/2200 (epoch 45.636) train_loss=431.50436401 time/batch=17.15s
503/2200 (epoch 45.727) train_loss=435.21926880 time/batch=17.48s
504/2200 (epoch 45.818) train_loss=904.06427002 time/batch=8.68s
505/2200 (epoch 45.909) train_loss=793.24261475 time/batch=19.42s
506/2200 (epoch 46.000) train_loss=933.17901611 time/batch=10.14s
setting learning rate to 0.0014009
507/2200 (epoch 46.091) train_loss=679.62518311 time/batch=6.37s
508/2200 (epoch 46.182) train_loss=1162.69909668 time/batch=11.25s
509/2200 (epoch 46.273) train_loss=362.70651245 time/batch=3.45s
510/2200 (epoch 46.364) train_loss=950.31402588 time/batch=8.91s
511/2200 (epoch 46.455) train_loss=509.04013062 time/batch=16.85s
512/2200 (epoch 46.545) train_loss=605.08288574 time/batch=6.61s
513/2200 (epoch 46.636) train_loss=677.44793701 time/batch=28.52s
514/2200 (epoch 46.727) train_loss=1140.58850098 time/batch=14.20s
515/2200 (epoch 46.818) train_loss=640.42852783 time/batch=19.18s
516/2200 (epoch 46.909) train_loss=460.02972412 time/batch=6.82s
517/2200 (epoch 47.000) train_loss=837.55267334 time/batch=7.09s
setting learning rate to 0.0013589
518/2200 (epoch 47.091) train_loss=868.78430176 time/batch=8.10s
519/2200 (epoch 47.182) train_loss=840.20288086 time/batch=7.92s
520/2200 (epoch 47.273) train_loss=765.46441650 time/batch=19.41s
521/2200 (epoch 47.364) train_loss=591.14147949 time/batch=5.70s
522/2200 (epoch 47.455) train_loss=786.52301025 time/batch=8.42s
523/2200 (epoch 47.545) train_loss=1236.05676270 time/batch=13.55s
524/2200 (epoch 47.636) train_loss=676.65832520 time/batch=26.31s
525/2200 (epoch 47.727) train_loss=363.41461182 time/batch=3.33s
526/2200 (epoch 47.818) train_loss=1038.88574219 time/batch=10.36s
527/2200 (epoch 47.909) train_loss=515.69580078 time/batch=18.12s
528/2200 (epoch 48.000) train_loss=503.88333130 time/batch=4.63s
setting learning rate to 0.0013181
529/2200 (epoch 48.091) train_loss=1137.28051758 time/batch=11.29s
530/2200 (epoch 48.182) train_loss=824.09411621 time/batch=20.35s
531/2200 (epoch 48.273) train_loss=841.21606445 time/batch=7.50s
532/2200 (epoch 48.364) train_loss=551.27026367 time/batch=5.25s
533/2200 (epoch 48.455) train_loss=1027.27929688 time/batch=11.62s
534/2200 (epoch 48.545) train_loss=1059.88281250 time/batch=13.97s
535/2200 (epoch 48.636) train_loss=394.99227905 time/batch=16.41s
536/2200 (epoch 48.727) train_loss=548.18176270 time/batch=5.60s
537/2200 (epoch 48.818) train_loss=706.44036865 time/batch=7.43s
538/2200 (epoch 48.909) train_loss=592.78771973 time/batch=26.58s
539/2200 (epoch 49.000) train_loss=500.72622681 time/batch=16.46s
setting learning rate to 0.0012786
540/2200 (epoch 49.091) train_loss=839.66076660 time/batch=7.87s
541/2200 (epoch 49.182) train_loss=1135.42431641 time/batch=11.23s
542/2200 (epoch 49.273) train_loss=507.75186157 time/batch=4.80s
543/2200 (epoch 49.364) train_loss=396.16629028 time/batch=17.28s
544/2200 (epoch 49.455) train_loss=618.42938232 time/batch=29.13s
545/2200 (epoch 49.545) train_loss=695.97320557 time/batch=6.33s
546/2200 (epoch 49.636) train_loss=879.30523682 time/batch=8.49s
547/2200 (epoch 49.727) train_loss=434.96618652 time/batch=4.12s
548/2200 (epoch 49.818) train_loss=654.44366455 time/batch=6.64s
549/2200 (epoch 49.909) train_loss=634.80926514 time/batch=19.42s
550/2200 (epoch 50.000) train_loss=944.06378174 time/batch=17.77s
setting learning rate to 0.0012402
  saved to metadata/configSample--20250116-172737.pkl
551/2200 (epoch 50.091) train_loss=838.94702148 time/batch=7.72s
552/2200 (epoch 50.182) train_loss=890.11212158 time/batch=8.84s
553/2200 (epoch 50.273) train_loss=432.87738037 time/batch=17.44s
554/2200 (epoch 50.364) train_loss=942.51037598 time/batch=8.94s
555/2200 (epoch 50.455) train_loss=502.34988403 time/batch=16.90s
556/2200 (epoch 50.545) train_loss=657.20025635 time/batch=6.33s
557/2200 (epoch 50.636) train_loss=503.64761353 time/batch=4.76s
558/2200 (epoch 50.727) train_loss=394.31350708 time/batch=4.83s
559/2200 (epoch 50.818) train_loss=832.88256836 time/batch=20.30s
560/2200 (epoch 50.909) train_loss=897.55407715 time/batch=10.90s
561/2200 (epoch 51.000) train_loss=832.52557373 time/batch=29.38s
setting learning rate to 0.0012030
562/2200 (epoch 51.091) train_loss=786.00567627 time/batch=19.23s
563/2200 (epoch 51.182) train_loss=1144.24926758 time/batch=11.69s
564/2200 (epoch 51.273) train_loss=704.52130127 time/batch=6.85s
565/2200 (epoch 51.364) train_loss=663.75598145 time/batch=27.30s
566/2200 (epoch 51.455) train_loss=853.80865479 time/batch=7.59s
567/2200 (epoch 51.545) train_loss=1217.90002441 time/batch=13.46s
568/2200 (epoch 51.636) train_loss=357.82955933 time/batch=3.37s
569/2200 (epoch 51.727) train_loss=513.39770508 time/batch=4.44s
570/2200 (epoch 51.818) train_loss=422.85269165 time/batch=4.01s
571/2200 (epoch 51.909) train_loss=531.32434082 time/batch=5.42s
572/2200 (epoch 52.000) train_loss=855.62652588 time/batch=8.81s
setting learning rate to 0.0011669
573/2200 (epoch 52.091) train_loss=1026.20703125 time/batch=10.06s
574/2200 (epoch 52.182) train_loss=686.67102051 time/batch=6.63s
575/2200 (epoch 52.273) train_loss=743.99682617 time/batch=19.85s
576/2200 (epoch 52.364) train_loss=1238.47558594 time/batch=13.78s
577/2200 (epoch 52.455) train_loss=527.25994873 time/batch=4.52s
578/2200 (epoch 52.545) train_loss=834.91864014 time/batch=7.57s
579/2200 (epoch 52.636) train_loss=377.01757812 time/batch=3.65s
580/2200 (epoch 52.727) train_loss=658.05249023 time/batch=27.28s
581/2200 (epoch 52.818) train_loss=654.45349121 time/batch=7.92s
582/2200 (epoch 52.909) train_loss=507.85781860 time/batch=18.16s
583/2200 (epoch 53.000) train_loss=762.15563965 time/batch=9.58s
setting learning rate to 0.0011319
584/2200 (epoch 53.091) train_loss=509.17251587 time/batch=4.88s
585/2200 (epoch 53.182) train_loss=853.15399170 time/batch=8.19s
586/2200 (epoch 53.273) train_loss=808.78454590 time/batch=19.61s
587/2200 (epoch 53.364) train_loss=564.45642090 time/batch=17.85s
588/2200 (epoch 53.455) train_loss=1100.99597168 time/batch=10.41s
589/2200 (epoch 53.545) train_loss=661.39300537 time/batch=6.32s
590/2200 (epoch 53.636) train_loss=520.84588623 time/batch=6.33s
591/2200 (epoch 53.727) train_loss=1234.57421875 time/batch=14.33s
592/2200 (epoch 53.818) train_loss=395.77630615 time/batch=17.56s
593/2200 (epoch 53.909) train_loss=377.97705078 time/batch=3.70s
594/2200 (epoch 54.000) train_loss=772.14215088 time/batch=8.90s
setting learning rate to 0.0010980
595/2200 (epoch 54.091) train_loss=374.18246460 time/batch=16.51s
596/2200 (epoch 54.182) train_loss=511.73519897 time/batch=4.78s
597/2200 (epoch 54.273) train_loss=509.29348755 time/batch=18.14s
598/2200 (epoch 54.364) train_loss=386.93344116 time/batch=3.77s
599/2200 (epoch 54.455) train_loss=878.60009766 time/batch=8.04s
600/2200 (epoch 54.545) train_loss=1232.62683105 time/batch=13.59s
601/2200 (epoch 54.636) train_loss=1098.95349121 time/batch=9.78s
602/2200 (epoch 54.727) train_loss=672.90167236 time/batch=5.95s
603/2200 (epoch 54.818) train_loss=553.82427979 time/batch=5.48s
604/2200 (epoch 54.909) train_loss=843.14868164 time/batch=8.30s
605/2200 (epoch 55.000) train_loss=641.18865967 time/batch=20.53s
setting learning rate to 0.0010650
606/2200 (epoch 55.091) train_loss=517.66094971 time/batch=18.13s
607/2200 (epoch 55.182) train_loss=895.14910889 time/batch=8.65s
608/2200 (epoch 55.273) train_loss=1177.95495605 time/batch=11.98s
609/2200 (epoch 55.364) train_loss=847.68865967 time/batch=7.66s
610/2200 (epoch 55.455) train_loss=1130.22424316 time/batch=14.76s
611/2200 (epoch 55.545) train_loss=567.13244629 time/batch=5.78s
612/2200 (epoch 55.636) train_loss=393.91732788 time/batch=17.34s
613/2200 (epoch 55.727) train_loss=623.31805420 time/batch=26.38s
614/2200 (epoch 55.818) train_loss=430.27987671 time/batch=4.24s
615/2200 (epoch 55.909) train_loss=611.57836914 time/batch=5.81s
616/2200 (epoch 56.000) train_loss=761.98382568 time/batch=19.24s
setting learning rate to 0.0010331
617/2200 (epoch 56.091) train_loss=530.47735596 time/batch=5.07s
618/2200 (epoch 56.182) train_loss=676.35400391 time/batch=6.56s
619/2200 (epoch 56.273) train_loss=550.14111328 time/batch=17.24s
620/2200 (epoch 56.364) train_loss=573.60968018 time/batch=6.82s
621/2200 (epoch 56.455) train_loss=998.20721436 time/batch=9.94s
622/2200 (epoch 56.545) train_loss=645.60723877 time/batch=29.38s
623/2200 (epoch 56.636) train_loss=645.08825684 time/batch=20.47s
624/2200 (epoch 56.727) train_loss=819.22167969 time/batch=7.81s
625/2200 (epoch 56.818) train_loss=1039.80688477 time/batch=10.33s
626/2200 (epoch 56.909) train_loss=830.50744629 time/batch=10.94s
627/2200 (epoch 57.000) train_loss=556.66894531 time/batch=11.20s
setting learning rate to 0.0010021
628/2200 (epoch 57.091) train_loss=872.62078857 time/batch=8.61s
629/2200 (epoch 57.182) train_loss=405.21621704 time/batch=17.03s
630/2200 (epoch 57.273) train_loss=514.11834717 time/batch=4.97s
631/2200 (epoch 57.364) train_loss=624.78448486 time/batch=26.98s
632/2200 (epoch 57.455) train_loss=1140.26318359 time/batch=10.60s
633/2200 (epoch 57.545) train_loss=519.95446777 time/batch=18.74s
634/2200 (epoch 57.636) train_loss=1153.24987793 time/batch=12.25s
635/2200 (epoch 57.727) train_loss=650.54931641 time/batch=6.16s
636/2200 (epoch 57.818) train_loss=772.49932861 time/batch=20.63s
637/2200 (epoch 57.909) train_loss=792.40252686 time/batch=7.59s
638/2200 (epoch 58.000) train_loss=675.40899658 time/batch=13.20s
setting learning rate to 0.0009720
639/2200 (epoch 58.091) train_loss=1094.74707031 time/batch=10.14s
640/2200 (epoch 58.182) train_loss=493.98861694 time/batch=4.06s
641/2200 (epoch 58.273) train_loss=1213.79162598 time/batch=13.89s
642/2200 (epoch 58.364) train_loss=350.20819092 time/batch=3.00s
643/2200 (epoch 58.455) train_loss=651.05065918 time/batch=27.80s
644/2200 (epoch 58.545) train_loss=575.35034180 time/batch=17.57s
645/2200 (epoch 58.636) train_loss=893.93261719 time/batch=8.52s
646/2200 (epoch 58.727) train_loss=754.09552002 time/batch=19.46s
647/2200 (epoch 58.818) train_loss=799.79187012 time/batch=7.76s
648/2200 (epoch 58.909) train_loss=655.70483398 time/batch=6.14s
649/2200 (epoch 59.000) train_loss=418.61505127 time/batch=3.73s
setting learning rate to 0.0009429
650/2200 (epoch 59.091) train_loss=548.13745117 time/batch=5.66s
651/2200 (epoch 59.182) train_loss=655.53912354 time/batch=5.60s
652/2200 (epoch 59.273) train_loss=997.43457031 time/batch=9.80s
653/2200 (epoch 59.364) train_loss=397.61621094 time/batch=17.16s
654/2200 (epoch 59.455) train_loss=1099.98437500 time/batch=10.60s
655/2200 (epoch 59.545) train_loss=1123.32226562 time/batch=14.82s
656/2200 (epoch 59.636) train_loss=630.63555908 time/batch=27.56s
657/2200 (epoch 59.727) train_loss=469.24310303 time/batch=4.23s
658/2200 (epoch 59.818) train_loss=828.71667480 time/batch=7.40s
659/2200 (epoch 59.909) train_loss=615.74163818 time/batch=6.13s
660/2200 (epoch 60.000) train_loss=667.33203125 time/batch=19.95s
setting learning rate to 0.0009146
  saved to metadata/configSample--20250116-172737.pkl
661/2200 (epoch 60.091) train_loss=648.49011230 time/batch=5.94s
662/2200 (epoch 60.182) train_loss=540.26000977 time/batch=5.97s
663/2200 (epoch 60.273) train_loss=644.43267822 time/batch=26.93s
664/2200 (epoch 60.364) train_loss=899.05841064 time/batch=8.72s
665/2200 (epoch 60.455) train_loss=914.61749268 time/batch=9.61s
666/2200 (epoch 60.545) train_loss=524.23889160 time/batch=18.51s
667/2200 (epoch 60.636) train_loss=932.52282715 time/batch=9.92s
668/2200 (epoch 60.727) train_loss=423.82644653 time/batch=4.39s
669/2200 (epoch 60.818) train_loss=858.49517822 time/batch=20.82s
670/2200 (epoch 60.909) train_loss=434.95233154 time/batch=6.28s
671/2200 (epoch 61.000) train_loss=1032.83325195 time/batch=12.05s
setting learning rate to 0.0008871
672/2200 (epoch 61.091) train_loss=1041.74548340 time/batch=9.57s
673/2200 (epoch 61.182) train_loss=571.01647949 time/batch=5.61s
674/2200 (epoch 61.273) train_loss=1198.84167480 time/batch=11.65s
675/2200 (epoch 61.364) train_loss=645.96069336 time/batch=27.43s
676/2200 (epoch 61.455) train_loss=832.01416016 time/batch=7.24s
677/2200 (epoch 61.545) train_loss=542.36755371 time/batch=17.54s
678/2200 (epoch 61.636) train_loss=988.43841553 time/batch=14.20s
679/2200 (epoch 61.727) train_loss=356.69763184 time/batch=3.51s
680/2200 (epoch 61.818) train_loss=787.33099365 time/batch=20.63s
681/2200 (epoch 61.909) train_loss=416.46557617 time/batch=4.00s
682/2200 (epoch 62.000) train_loss=655.89941406 time/batch=6.43s
setting learning rate to 0.0008605
683/2200 (epoch 62.091) train_loss=985.80731201 time/batch=9.50s
684/2200 (epoch 62.182) train_loss=878.27954102 time/batch=9.73s
685/2200 (epoch 62.273) train_loss=575.94122314 time/batch=5.95s
686/2200 (epoch 62.364) train_loss=774.52478027 time/batch=7.37s
687/2200 (epoch 62.455) train_loss=514.43615723 time/batch=18.47s
688/2200 (epoch 62.545) train_loss=635.88153076 time/batch=29.18s
689/2200 (epoch 62.636) train_loss=752.51501465 time/batch=20.18s
690/2200 (epoch 62.727) train_loss=1212.26135254 time/batch=13.53s
691/2200 (epoch 62.818) train_loss=368.10220337 time/batch=3.52s
692/2200 (epoch 62.909) train_loss=397.17349243 time/batch=4.21s
693/2200 (epoch 63.000) train_loss=843.94946289 time/batch=10.66s
setting learning rate to 0.0008347
694/2200 (epoch 63.091) train_loss=941.14849854 time/batch=9.65s
695/2200 (epoch 63.182) train_loss=377.43478394 time/batch=3.67s
696/2200 (epoch 63.273) train_loss=1205.29199219 time/batch=14.68s
697/2200 (epoch 63.364) train_loss=635.86083984 time/batch=28.10s
698/2200 (epoch 63.455) train_loss=554.36163330 time/batch=5.55s
699/2200 (epoch 63.545) train_loss=653.26776123 time/batch=6.49s
700/2200 (epoch 63.636) train_loss=521.52301025 time/batch=17.61s
701/2200 (epoch 63.727) train_loss=375.46405029 time/batch=4.07s
702/2200 (epoch 63.818) train_loss=865.83459473 time/batch=9.24s
703/2200 (epoch 63.909) train_loss=980.41717529 time/batch=9.96s
704/2200 (epoch 64.000) train_loss=785.08599854 time/batch=20.34s
setting learning rate to 0.0008097
705/2200 (epoch 64.091) train_loss=626.44866943 time/batch=28.27s
706/2200 (epoch 64.182) train_loss=1211.68518066 time/batch=13.27s
707/2200 (epoch 64.273) train_loss=771.61254883 time/batch=20.76s
708/2200 (epoch 64.364) train_loss=662.90740967 time/batch=6.51s
709/2200 (epoch 64.455) train_loss=521.84692383 time/batch=5.15s
710/2200 (epoch 64.545) train_loss=730.98150635 time/batch=7.38s
711/2200 (epoch 64.636) train_loss=982.75915527 time/batch=10.09s
712/2200 (epoch 64.727) train_loss=832.00634766 time/batch=6976.83s
713/2200 (epoch 64.818) train_loss=349.33941650 time/batch=2.83s
714/2200 (epoch 64.909) train_loss=817.79364014 time/batch=8.70s
715/2200 (epoch 65.000) train_loss=475.94433594 time/batch=16.47s
setting learning rate to 0.0007854
716/2200 (epoch 65.091) train_loss=378.54113770 time/batch=15.33s
717/2200 (epoch 65.182) train_loss=350.32965088 time/batch=3.07s
718/2200 (epoch 65.273) train_loss=894.13201904 time/batch=7.91s
719/2200 (epoch 65.364) train_loss=509.76098633 time/batch=16.56s
720/2200 (epoch 65.455) train_loss=661.81982422 time/batch=26.48s
721/2200 (epoch 65.545) train_loss=541.97875977 time/batch=4.78s
722/2200 (epoch 65.636) train_loss=852.30474854 time/batch=9.04s
723/2200 (epoch 65.727) train_loss=1208.95983887 time/batch=27.20s
724/2200 (epoch 65.818) train_loss=646.87139893 time/batch=11.23s
725/2200 (epoch 65.909) train_loss=738.75726318 time/batch=38.53s
726/2200 (epoch 66.000) train_loss=1063.79956055 time/batch=19.36s
setting learning rate to 0.0007618
727/2200 (epoch 66.091) train_loss=382.65087891 time/batch=31.76s
728/2200 (epoch 66.182) train_loss=1042.72509766 time/batch=19.32s
729/2200 (epoch 66.273) train_loss=1194.54357910 time/batch=26.41s
730/2200 (epoch 66.364) train_loss=806.99743652 time/batch=14.71s
731/2200 (epoch 66.455) train_loss=420.32287598 time/batch=7.70s
732/2200 (epoch 66.545) train_loss=467.56518555 time/batch=34.30s
733/2200 (epoch 66.636) train_loss=620.97436523 time/batch=11.35s
734/2200 (epoch 66.727) train_loss=650.19934082 time/batch=54.64s
735/2200 (epoch 66.818) train_loss=754.96148682 time/batch=39.22s
736/2200 (epoch 66.909) train_loss=729.02667236 time/batch=15.06s
737/2200 (epoch 67.000) train_loss=598.98767090 time/batch=15.54s
setting learning rate to 0.0007390
738/2200 (epoch 67.091) train_loss=812.18762207 time/batch=14.77s
739/2200 (epoch 67.182) train_loss=481.70288086 time/batch=34.49s
740/2200 (epoch 67.273) train_loss=661.23620605 time/batch=12.09s
741/2200 (epoch 67.364) train_loss=527.27642822 time/batch=10.11s
742/2200 (epoch 67.455) train_loss=742.28283691 time/batch=39.04s
743/2200 (epoch 67.545) train_loss=807.33502197 time/batch=15.93s
744/2200 (epoch 67.636) train_loss=1195.38244629 time/batch=26.43s
745/2200 (epoch 67.727) train_loss=755.10174561 time/batch=17.07s
746/2200 (epoch 67.818) train_loss=635.75079346 time/batch=54.56s
747/2200 (epoch 67.909) train_loss=346.28549194 time/batch=6.69s
748/2200 (epoch 68.000) train_loss=582.24578857 time/batch=18.08s
setting learning rate to 0.0007168
749/2200 (epoch 68.091) train_loss=1158.31311035 time/batch=22.31s
750/2200 (epoch 68.182) train_loss=964.31280518 time/batch=17.96s
751/2200 (epoch 68.273) train_loss=503.09060669 time/batch=34.46s
752/2200 (epoch 68.364) train_loss=649.07257080 time/batch=11.74s
753/2200 (epoch 68.455) train_loss=444.18228149 time/batch=8.65s
754/2200 (epoch 68.545) train_loss=978.45837402 time/batch=23.44s
755/2200 (epoch 68.636) train_loss=880.56927490 time/batch=26.41s
756/2200 (epoch 68.727) train_loss=776.93945312 time/batch=39.21s
757/2200 (epoch 68.818) train_loss=417.73507690 time/batch=32.23s
758/2200 (epoch 68.909) train_loss=599.83587646 time/batch=12.17s
759/2200 (epoch 69.000) train_loss=556.67382812 time/batch=54.60s
setting learning rate to 0.0006953
760/2200 (epoch 69.091) train_loss=1192.73461914 time/batch=26.61s
761/2200 (epoch 69.182) train_loss=525.62530518 time/batch=9.78s
762/2200 (epoch 69.273) train_loss=744.72863770 time/batch=39.26s
763/2200 (epoch 69.364) train_loss=1014.42041016 time/batch=19.17s
764/2200 (epoch 69.455) train_loss=640.05541992 time/batch=54.45s
765/2200 (epoch 69.545) train_loss=349.41531372 time/batch=6.66s
766/2200 (epoch 69.636) train_loss=657.14617920 time/batch=11.66s
767/2200 (epoch 69.727) train_loss=623.37969971 time/batch=13.34s
768/2200 (epoch 69.818) train_loss=410.02661133 time/batch=7.73s
769/2200 (epoch 69.909) train_loss=866.97949219 time/batch=16.15s
770/2200 (epoch 70.000) train_loss=629.05694580 time/batch=34.38s
setting learning rate to 0.0006744
  saved to metadata/configSample--20250116-172737.pkl
771/2200 (epoch 70.091) train_loss=571.31591797 time/batch=10.77s
772/2200 (epoch 70.182) train_loss=1167.75671387 time/batch=22.52s
773/2200 (epoch 70.273) train_loss=765.61669922 time/batch=39.04s
774/2200 (epoch 70.364) train_loss=859.76367188 time/batch=16.26s
775/2200 (epoch 70.455) train_loss=607.37225342 time/batch=11.62s
776/2200 (epoch 70.545) train_loss=753.19805908 time/batch=14.43s
777/2200 (epoch 70.636) train_loss=1104.63183594 time/batch=26.41s
778/2200 (epoch 70.727) train_loss=571.55682373 time/batch=14.68s
779/2200 (epoch 70.818) train_loss=545.61114502 time/batch=34.43s
780/2200 (epoch 70.909) train_loss=385.84674072 time/batch=32.76s
781/2200 (epoch 71.000) train_loss=375.42031860 time/batch=6.84s
setting learning rate to 0.0006542
782/2200 (epoch 71.091) train_loss=1212.20776367 time/batch=26.72s
783/2200 (epoch 71.182) train_loss=642.65789795 time/batch=11.34s
784/2200 (epoch 71.273) train_loss=862.82592773 time/batch=16.11s
785/2200 (epoch 71.364) train_loss=519.20733643 time/batch=29.19s
786/2200 (epoch 71.455) train_loss=526.51379395 time/batch=4.34s
787/2200 (epoch 71.545) train_loss=999.96099854 time/batch=8.18s
788/2200 (epoch 71.636) train_loss=609.94964600 time/batch=5.28s
789/2200 (epoch 71.727) train_loss=688.47619629 time/batch=16.99s
790/2200 (epoch 71.818) train_loss=401.25265503 time/batch=14.31s
791/2200 (epoch 71.909) train_loss=341.15197754 time/batch=2.91s
792/2200 (epoch 72.000) train_loss=910.90850830 time/batch=8.52s
setting learning rate to 0.0006346
793/2200 (epoch 72.091) train_loss=1042.50207520 time/batch=8.32s
794/2200 (epoch 72.182) train_loss=1100.19274902 time/batch=9.35s
795/2200 (epoch 72.273) train_loss=770.24914551 time/batch=16.97s
796/2200 (epoch 72.364) train_loss=504.80020142 time/batch=3.90s
797/2200 (epoch 72.455) train_loss=338.12847900 time/batch=2.71s
798/2200 (epoch 72.545) train_loss=627.16699219 time/batch=23.70s
799/2200 (epoch 72.636) train_loss=507.73440552 time/batch=4.42s
800/2200 (epoch 72.727) train_loss=1020.05456543 time/batch=11.33s
801/2200 (epoch 72.818) train_loss=794.45080566 time/batch=6.40s
802/2200 (epoch 72.909) train_loss=506.09582520 time/batch=14.70s
803/2200 (epoch 73.000) train_loss=548.63555908 time/batch=4.90s
setting learning rate to 0.0006155
804/2200 (epoch 73.091) train_loss=614.24633789 time/batch=4.95s
805/2200 (epoch 73.182) train_loss=351.95327759 time/batch=2.95s
806/2200 (epoch 73.273) train_loss=457.25756836 time/batch=14.80s
807/2200 (epoch 73.364) train_loss=444.56817627 time/batch=3.83s
808/2200 (epoch 73.455) train_loss=1131.59790039 time/batch=9.38s
809/2200 (epoch 73.545) train_loss=840.23675537 time/batch=6.45s
810/2200 (epoch 73.636) train_loss=802.24279785 time/batch=16.93s
811/2200 (epoch 73.727) train_loss=422.05166626 time/batch=14.17s
812/2200 (epoch 73.818) train_loss=779.28698730 time/batch=7.05s
813/2200 (epoch 73.909) train_loss=1099.70092773 time/batch=10.36s
814/2200 (epoch 74.000) train_loss=696.06231689 time/batch=11.46s
setting learning rate to 0.0005971
815/2200 (epoch 74.091) train_loss=1179.91210938 time/batch=11.36s
816/2200 (epoch 74.182) train_loss=577.36920166 time/batch=4.66s
817/2200 (epoch 74.273) train_loss=1055.04492188 time/batch=8.47s
818/2200 (epoch 74.364) train_loss=873.27441406 time/batch=7.27s
819/2200 (epoch 74.455) train_loss=762.21588135 time/batch=17.00s
820/2200 (epoch 74.545) train_loss=587.74438477 time/batch=5.16s
821/2200 (epoch 74.636) train_loss=577.25903320 time/batch=5.76s
822/2200 (epoch 74.727) train_loss=561.94073486 time/batch=14.94s
823/2200 (epoch 74.818) train_loss=624.91436768 time/batch=24.28s
824/2200 (epoch 74.909) train_loss=392.98587036 time/batch=5.99s
825/2200 (epoch 75.000) train_loss=453.76770020 time/batch=6.20s
setting learning rate to 0.0005792
826/2200 (epoch 75.091) train_loss=848.50622559 time/batch=6.53s
827/2200 (epoch 75.182) train_loss=360.99618530 time/batch=16.16s
828/2200 (epoch 75.273) train_loss=1127.82482910 time/batch=21.77s
829/2200 (epoch 75.364) train_loss=376.70544434 time/batch=6.96s
830/2200 (epoch 75.455) train_loss=548.71160889 time/batch=10.07s
831/2200 (epoch 75.545) train_loss=823.32141113 time/batch=39.26s
832/2200 (epoch 75.636) train_loss=1158.32714844 time/batch=26.62s
833/2200 (epoch 75.727) train_loss=650.88958740 time/batch=12.05s
834/2200 (epoch 75.818) train_loss=464.26577759 time/batch=34.61s
835/2200 (epoch 75.909) train_loss=658.88250732 time/batch=15.55s
836/2200 (epoch 76.000) train_loss=502.32467651 time/batch=15.88s
setting learning rate to 0.0005618
837/2200 (epoch 76.091) train_loss=761.15777588 time/batch=38.34s
838/2200 (epoch 76.182) train_loss=489.07232666 time/batch=15.25s
839/2200 (epoch 76.273) train_loss=627.08575439 time/batch=36.85s
840/2200 (epoch 76.364) train_loss=1202.04833984 time/batch=13.08s
841/2200 (epoch 76.455) train_loss=355.28988647 time/batch=3.12s
842/2200 (epoch 76.545) train_loss=1024.00683594 time/batch=8.76s
843/2200 (epoch 76.636) train_loss=411.63113403 time/batch=3.93s
844/2200 (epoch 76.727) train_loss=538.23754883 time/batch=4.67s
845/2200 (epoch 76.818) train_loss=846.20153809 time/batch=7.32s
846/2200 (epoch 76.909) train_loss=861.94006348 time/batch=8.89s
847/2200 (epoch 77.000) train_loss=640.81890869 time/batch=5.29s
setting learning rate to 0.0005449
848/2200 (epoch 77.091) train_loss=1113.73034668 time/batch=9.77s
849/2200 (epoch 77.182) train_loss=749.85748291 time/batch=17.93s
850/2200 (epoch 77.273) train_loss=829.46075439 time/batch=7.16s
851/2200 (epoch 77.364) train_loss=636.09503174 time/batch=24.81s
852/2200 (epoch 77.455) train_loss=658.71179199 time/batch=5.95s
853/2200 (epoch 77.545) train_loss=807.10363770 time/batch=7.46s
854/2200 (epoch 77.636) train_loss=490.51724243 time/batch=15.61s
855/2200 (epoch 77.727) train_loss=337.51840210 time/batch=2.96s
856/2200 (epoch 77.818) train_loss=1129.35632324 time/batch=11.96s
857/2200 (epoch 77.909) train_loss=558.17822266 time/batch=5.91s
858/2200 (epoch 78.000) train_loss=528.77673340 time/batch=7.53s
setting learning rate to 0.0005286
859/2200 (epoch 78.091) train_loss=1056.03076172 time/batch=8.92s
860/2200 (epoch 78.182) train_loss=378.42813110 time/batch=14.70s
861/2200 (epoch 78.273) train_loss=515.49719238 time/batch=15.61s
862/2200 (epoch 78.364) train_loss=352.55331421 time/batch=3.04s
863/2200 (epoch 78.455) train_loss=637.65069580 time/batch=24.67s
864/2200 (epoch 78.545) train_loss=516.51574707 time/batch=4.38s
865/2200 (epoch 78.636) train_loss=750.02624512 time/batch=6.41s
866/2200 (epoch 78.727) train_loss=663.81433105 time/batch=5.39s
867/2200 (epoch 78.818) train_loss=1180.17541504 time/batch=11.90s
868/2200 (epoch 78.909) train_loss=826.90484619 time/batch=7.09s
869/2200 (epoch 79.000) train_loss=877.85784912 time/batch=17.62s
setting learning rate to 0.0005127
870/2200 (epoch 79.091) train_loss=934.08007812 time/batch=7.89s
871/2200 (epoch 79.182) train_loss=1007.63116455 time/batch=8.92s
872/2200 (epoch 79.273) train_loss=611.92816162 time/batch=24.97s
873/2200 (epoch 79.364) train_loss=751.74792480 time/batch=17.93s
874/2200 (epoch 79.455) train_loss=637.59967041 time/batch=5.26s
875/2200 (epoch 79.545) train_loss=508.27914429 time/batch=4.31s
876/2200 (epoch 79.636) train_loss=485.33227539 time/batch=4.66s
877/2200 (epoch 79.727) train_loss=334.83914185 time/batch=2.97s
878/2200 (epoch 79.818) train_loss=997.04333496 time/batch=9.69s
879/2200 (epoch 79.909) train_loss=970.37030029 time/batch=12.00s
880/2200 (epoch 80.000) train_loss=414.12512207 time/batch=3.48s
setting learning rate to 0.0004973
  saved to metadata/configSample--20250116-172737.pkl
881/2200 (epoch 80.091) train_loss=798.35925293 time/batch=6.75s
882/2200 (epoch 80.182) train_loss=549.43951416 time/batch=4.74s
883/2200 (epoch 80.273) train_loss=736.79278564 time/batch=17.77s
884/2200 (epoch 80.364) train_loss=395.08346558 time/batch=3.46s
885/2200 (epoch 80.455) train_loss=1023.68737793 time/batch=8.79s
886/2200 (epoch 80.545) train_loss=615.31384277 time/batch=24.57s
887/2200 (epoch 80.636) train_loss=961.66033936 time/batch=9.16s
888/2200 (epoch 80.727) train_loss=1106.44128418 time/batch=11.89s
889/2200 (epoch 80.818) train_loss=691.55999756 time/batch=5.98s
890/2200 (epoch 80.909) train_loss=343.03894043 time/batch=3.42s
891/2200 (epoch 81.000) train_loss=516.16290283 time/batch=15.42s
setting learning rate to 0.0004824
892/2200 (epoch 81.091) train_loss=974.72186279 time/batch=8.31s
893/2200 (epoch 81.182) train_loss=513.06079102 time/batch=15.46s
894/2200 (epoch 81.273) train_loss=568.93872070 time/batch=4.80s
895/2200 (epoch 81.364) train_loss=758.93829346 time/batch=17.48s
896/2200 (epoch 81.455) train_loss=392.85205078 time/batch=14.47s
897/2200 (epoch 81.545) train_loss=514.44665527 time/batch=5.06s
898/2200 (epoch 81.636) train_loss=586.48846436 time/batch=24.42s
899/2200 (epoch 81.727) train_loss=878.89923096 time/batch=6.89s
900/2200 (epoch 81.818) train_loss=1404.40893555 time/batch=9.76s
901/2200 (epoch 81.909) train_loss=1002.08569336 time/batch=11.91s
902/2200 (epoch 82.000) train_loss=482.83535767 time/batch=5.09s
setting learning rate to 0.0004679
903/2200 (epoch 82.091) train_loss=515.48907471 time/batch=4.37s
904/2200 (epoch 82.182) train_loss=385.99240112 time/batch=14.60s
905/2200 (epoch 82.273) train_loss=575.80895996 time/batch=24.42s
906/2200 (epoch 82.364) train_loss=815.56475830 time/batch=6.65s
907/2200 (epoch 82.455) train_loss=1178.87036133 time/batch=11.84s
908/2200 (epoch 82.545) train_loss=903.03277588 time/batch=7.63s
909/2200 (epoch 82.636) train_loss=505.68469238 time/batch=15.41s
910/2200 (epoch 82.727) train_loss=669.03533936 time/batch=5.50s
911/2200 (epoch 82.818) train_loss=717.15545654 time/batch=17.51s
912/2200 (epoch 82.909) train_loss=402.89895630 time/batch=3.40s
913/2200 (epoch 83.000) train_loss=832.90789795 time/batch=8.24s
setting learning rate to 0.0004539
914/2200 (epoch 83.091) train_loss=1172.08557129 time/batch=11.85s
915/2200 (epoch 83.182) train_loss=389.26266479 time/batch=14.42s
916/2200 (epoch 83.273) train_loss=570.15625000 time/batch=24.46s
917/2200 (epoch 83.364) train_loss=398.99890137 time/batch=3.42s
918/2200 (epoch 83.455) train_loss=823.33197021 time/batch=6.92s
919/2200 (epoch 83.545) train_loss=533.64520264 time/batch=4.70s
920/2200 (epoch 83.636) train_loss=483.77319336 time/batch=4.69s
921/2200 (epoch 83.727) train_loss=651.16430664 time/batch=5.47s
922/2200 (epoch 83.818) train_loss=694.90484619 time/batch=17.58s
923/2200 (epoch 83.909) train_loss=1037.73425293 time/batch=8.78s
924/2200 (epoch 84.000) train_loss=917.84136963 time/batch=8.70s
setting learning rate to 0.0004403
925/2200 (epoch 84.091) train_loss=831.44696045 time/batch=6.86s
926/2200 (epoch 84.182) train_loss=396.57006836 time/batch=14.61s
927/2200 (epoch 84.273) train_loss=641.25738525 time/batch=5.34s
928/2200 (epoch 84.364) train_loss=568.09381104 time/batch=24.70s
929/2200 (epoch 84.455) train_loss=399.59149170 time/batch=3.45s
930/2200 (epoch 84.545) train_loss=771.73016357 time/batch=17.72s
931/2200 (epoch 84.636) train_loss=1111.37939453 time/batch=9.82s
932/2200 (epoch 84.727) train_loss=686.85693359 time/batch=6.96s
933/2200 (epoch 84.818) train_loss=891.50299072 time/batch=7.98s
934/2200 (epoch 84.909) train_loss=956.26068115 time/batch=11.83s
935/2200 (epoch 85.000) train_loss=490.62332153 time/batch=4.00s
setting learning rate to 0.0004271
936/2200 (epoch 85.091) train_loss=671.47399902 time/batch=5.57s
937/2200 (epoch 85.182) train_loss=834.64245605 time/batch=7.24s
938/2200 (epoch 85.273) train_loss=1058.51330566 time/batch=9.17s
939/2200 (epoch 85.364) train_loss=481.44107056 time/batch=15.51s
940/2200 (epoch 85.455) train_loss=1149.00952148 time/batch=11.97s
941/2200 (epoch 85.545) train_loss=703.88092041 time/batch=17.64s
942/2200 (epoch 85.636) train_loss=781.70935059 time/batch=7.35s
943/2200 (epoch 85.727) train_loss=626.08050537 time/batch=24.42s
944/2200 (epoch 85.818) train_loss=656.39691162 time/batch=7.52s
945/2200 (epoch 85.909) train_loss=497.29711914 time/batch=4.03s
946/2200 (epoch 86.000) train_loss=342.71621704 time/batch=2.97s
setting learning rate to 0.0004143
947/2200 (epoch 86.091) train_loss=1094.26232910 time/batch=9.52s
948/2200 (epoch 86.182) train_loss=359.02691650 time/batch=14.54s
949/2200 (epoch 86.273) train_loss=732.90380859 time/batch=17.74s
950/2200 (epoch 86.364) train_loss=978.51629639 time/batch=9.60s
951/2200 (epoch 86.455) train_loss=787.61676025 time/batch=6.58s
952/2200 (epoch 86.545) train_loss=813.76513672 time/batch=7.09s
953/2200 (epoch 86.636) train_loss=393.87179565 time/batch=3.30s
954/2200 (epoch 86.727) train_loss=540.31671143 time/batch=4.69s
955/2200 (epoch 86.818) train_loss=595.72900391 time/batch=24.39s
956/2200 (epoch 86.909) train_loss=502.67306519 time/batch=15.42s
957/2200 (epoch 87.000) train_loss=795.63262939 time/batch=10.34s
setting learning rate to 0.0004018
958/2200 (epoch 87.091) train_loss=1185.61547852 time/batch=11.86s
959/2200 (epoch 87.182) train_loss=1057.77404785 time/batch=8.89s
960/2200 (epoch 87.273) train_loss=476.17443848 time/batch=3.95s
961/2200 (epoch 87.364) train_loss=577.97637939 time/batch=24.63s
962/2200 (epoch 87.455) train_loss=737.18878174 time/batch=17.77s
963/2200 (epoch 87.545) train_loss=756.24981689 time/batch=6.52s
964/2200 (epoch 87.636) train_loss=853.77044678 time/batch=7.51s
965/2200 (epoch 87.727) train_loss=335.79058838 time/batch=2.94s
966/2200 (epoch 87.818) train_loss=493.45123291 time/batch=15.45s
967/2200 (epoch 87.909) train_loss=581.21203613 time/batch=5.11s
968/2200 (epoch 88.000) train_loss=518.11059570 time/batch=12.12s
setting learning rate to 0.0003898
969/2200 (epoch 88.091) train_loss=365.87014771 time/batch=3.25s
970/2200 (epoch 88.182) train_loss=510.94320679 time/batch=4.33s
971/2200 (epoch 88.273) train_loss=1171.95422363 time/batch=11.90s
972/2200 (epoch 88.364) train_loss=616.42028809 time/batch=5.22s
973/2200 (epoch 88.455) train_loss=1023.87805176 time/batch=8.46s
974/2200 (epoch 88.545) train_loss=858.37115479 time/batch=7.15s
975/2200 (epoch 88.636) train_loss=494.05389404 time/batch=15.38s
976/2200 (epoch 88.727) train_loss=732.82226562 time/batch=17.42s
977/2200 (epoch 88.818) train_loss=607.76910400 time/batch=5.99s
978/2200 (epoch 88.909) train_loss=606.86816406 time/batch=24.56s
979/2200 (epoch 89.000) train_loss=757.02746582 time/batch=8.74s
setting learning rate to 0.0003781
980/2200 (epoch 89.091) train_loss=1100.09704590 time/batch=9.65s
981/2200 (epoch 89.182) train_loss=506.96380615 time/batch=4.03s
982/2200 (epoch 89.273) train_loss=601.34020996 time/batch=5.11s
983/2200 (epoch 89.364) train_loss=817.11700439 time/batch=6.80s
984/2200 (epoch 89.455) train_loss=583.14764404 time/batch=5.42s
985/2200 (epoch 89.545) train_loss=789.84875488 time/batch=7.22s
986/2200 (epoch 89.636) train_loss=416.41525269 time/batch=3.52s
987/2200 (epoch 89.727) train_loss=1095.23840332 time/batch=10.73s
988/2200 (epoch 89.818) train_loss=826.74365234 time/batch=17.61s
989/2200 (epoch 89.909) train_loss=625.94561768 time/batch=24.38s
990/2200 (epoch 90.000) train_loss=342.08856201 time/batch=2.93s
setting learning rate to 0.0003668
  saved to metadata/configSample--20250116-172737.pkl
991/2200 (epoch 90.091) train_loss=1031.82775879 time/batch=8.69s
992/2200 (epoch 90.182) train_loss=498.20565796 time/batch=4.07s
993/2200 (epoch 90.273) train_loss=766.98352051 time/batch=6.51s
994/2200 (epoch 90.364) train_loss=1164.21215820 time/batch=11.91s
995/2200 (epoch 90.455) train_loss=568.67370605 time/batch=4.86s
996/2200 (epoch 90.545) train_loss=845.70257568 time/batch=17.61s
997/2200 (epoch 90.636) train_loss=485.67459106 time/batch=15.35s
998/2200 (epoch 90.727) train_loss=823.02264404 time/batch=8.85s
999/2200 (epoch 90.818) train_loss=370.56497192 time/batch=14.55s
Validating
    loss:	1418.468384

1000/2200 (epoch 90.909) train_loss=633.94085693 time/batch=66.19s
1001/2200 (epoch 91.000) train_loss=362.04455566 time/batch=3.09s
setting learning rate to 0.0003557
1002/2200 (epoch 91.091) train_loss=1227.00292969 time/batch=11.83s
1003/2200 (epoch 91.182) train_loss=759.81939697 time/batch=17.58s
1004/2200 (epoch 91.273) train_loss=1042.26416016 time/batch=8.90s
1005/2200 (epoch 91.364) train_loss=517.99291992 time/batch=4.39s
1006/2200 (epoch 91.455) train_loss=613.80407715 time/batch=24.73s
1007/2200 (epoch 91.545) train_loss=866.11749268 time/batch=7.44s
1008/2200 (epoch 91.636) train_loss=399.35025024 time/batch=3.48s
1009/2200 (epoch 91.727) train_loss=430.49279785 time/batch=15.40s
1010/2200 (epoch 91.818) train_loss=771.95764160 time/batch=6.60s
1011/2200 (epoch 91.909) train_loss=402.36914062 time/batch=4.37s
1012/2200 (epoch 92.000) train_loss=695.17700195 time/batch=6.65s
setting learning rate to 0.0003451
1013/2200 (epoch 92.091) train_loss=470.92727661 time/batch=3.95s
1014/2200 (epoch 92.182) train_loss=606.74011230 time/batch=24.55s
1015/2200 (epoch 92.273) train_loss=781.46466064 time/batch=17.67s
1016/2200 (epoch 92.364) train_loss=758.07257080 time/batch=6.61s
1017/2200 (epoch 92.455) train_loss=863.06842041 time/batch=7.52s
1018/2200 (epoch 92.545) train_loss=934.87377930 time/batch=8.49s
1019/2200 (epoch 92.636) train_loss=721.43115234 time/batch=8.89s
1020/2200 (epoch 92.727) train_loss=483.07949829 time/batch=15.60s
1021/2200 (epoch 92.818) train_loss=331.14315796 time/batch=2.93s
1022/2200 (epoch 92.909) train_loss=1166.47143555 time/batch=12.01s
1023/2200 (epoch 93.000) train_loss=525.57958984 time/batch=4.67s
setting learning rate to 0.0003347
1024/2200 (epoch 93.091) train_loss=673.19958496 time/batch=5.57s
1025/2200 (epoch 93.182) train_loss=498.40051270 time/batch=4.02s
1026/2200 (epoch 93.273) train_loss=1117.34313965 time/batch=10.15s
1027/2200 (epoch 93.364) train_loss=523.45593262 time/batch=4.66s
1028/2200 (epoch 93.455) train_loss=338.31063843 time/batch=3.03s
1029/2200 (epoch 93.545) train_loss=796.31738281 time/batch=6.69s
1030/2200 (epoch 93.636) train_loss=479.20095825 time/batch=15.47s
1031/2200 (epoch 93.727) train_loss=778.60839844 time/batch=7.13s
1032/2200 (epoch 93.818) train_loss=354.98715210 time/batch=14.60s
1033/2200 (epoch 93.909) train_loss=845.04174805 time/batch=17.60s
1034/2200 (epoch 94.000) train_loss=957.75628662 time/batch=24.73s
setting learning rate to 0.0003247
1035/2200 (epoch 94.091) train_loss=663.73815918 time/batch=5.48s
1036/2200 (epoch 94.182) train_loss=492.67254639 time/batch=4.11s
1037/2200 (epoch 94.273) train_loss=1161.14514160 time/batch=11.89s
1038/2200 (epoch 94.364) train_loss=729.61328125 time/batch=17.62s
1039/2200 (epoch 94.455) train_loss=615.32830811 time/batch=24.62s
1040/2200 (epoch 94.545) train_loss=483.88265991 time/batch=15.50s
1041/2200 (epoch 94.636) train_loss=1014.50018311 time/batch=8.73s
1042/2200 (epoch 94.727) train_loss=645.06976318 time/batch=6.03s
1043/2200 (epoch 94.818) train_loss=335.74777222 time/batch=3.01s
1044/2200 (epoch 94.909) train_loss=881.89001465 time/batch=8.92s
1045/2200 (epoch 95.000) train_loss=492.75671387 time/batch=6.40s
setting learning rate to 0.0003149
1046/2200 (epoch 95.091) train_loss=781.85137939 time/batch=6.72s
1047/2200 (epoch 95.182) train_loss=612.83465576 time/batch=24.45s
1048/2200 (epoch 95.273) train_loss=1061.55029297 time/batch=9.38s
1049/2200 (epoch 95.364) train_loss=1121.02331543 time/batch=11.86s
1050/2200 (epoch 95.455) train_loss=332.03497314 time/batch=2.91s
1051/2200 (epoch 95.545) train_loss=791.57080078 time/batch=6.86s
1052/2200 (epoch 95.636) train_loss=565.03881836 time/batch=4.69s
1053/2200 (epoch 95.727) train_loss=604.48175049 time/batch=5.12s
1054/2200 (epoch 95.818) train_loss=765.45861816 time/batch=17.62s
1055/2200 (epoch 95.909) train_loss=493.16885376 time/batch=15.59s
1056/2200 (epoch 96.000) train_loss=618.79406738 time/batch=7.50s
setting learning rate to 0.0003055
1057/2200 (epoch 96.091) train_loss=509.53576660 time/batch=4.41s
1058/2200 (epoch 96.182) train_loss=1139.57580566 time/batch=10.75s
1059/2200 (epoch 96.273) train_loss=519.20379639 time/batch=4.85s
1060/2200 (epoch 96.364) train_loss=1052.82446289 time/batch=12.04s
1061/2200 (epoch 96.455) train_loss=409.73852539 time/batch=3.53s
1062/2200 (epoch 96.545) train_loss=334.81063843 time/batch=2.99s
1063/2200 (epoch 96.636) train_loss=726.67956543 time/batch=17.70s
1064/2200 (epoch 96.727) train_loss=815.58404541 time/batch=6.85s
1065/2200 (epoch 96.818) train_loss=467.99688721 time/batch=15.65s
1066/2200 (epoch 96.909) train_loss=731.39263916 time/batch=7.17s
1067/2200 (epoch 97.000) train_loss=742.29370117 time/batch=7.49s
setting learning rate to 0.0002963
1068/2200 (epoch 97.091) train_loss=737.90039062 time/batch=6.56s
1069/2200 (epoch 97.182) train_loss=1230.71606445 time/batch=11.95s
1070/2200 (epoch 97.273) train_loss=751.04199219 time/batch=17.70s
1071/2200 (epoch 97.364) train_loss=373.19989014 time/batch=14.70s
1072/2200 (epoch 97.455) train_loss=520.95721436 time/batch=4.63s
1073/2200 (epoch 97.545) train_loss=1046.72875977 time/batch=8.98s
1074/2200 (epoch 97.636) train_loss=560.42559814 time/batch=24.88s
1075/2200 (epoch 97.727) train_loss=632.19995117 time/batch=5.28s
1076/2200 (epoch 97.818) train_loss=466.79229736 time/batch=15.54s
1077/2200 (epoch 97.909) train_loss=846.57952881 time/batch=7.51s
1078/2200 (epoch 98.000) train_loss=423.86520386 time/batch=3.88s
setting learning rate to 0.0002874
1079/2200 (epoch 98.091) train_loss=947.71508789 time/batch=8.30s
1080/2200 (epoch 98.182) train_loss=1029.37805176 time/batch=9.30s
1081/2200 (epoch 98.273) train_loss=755.95666504 time/batch=17.81s
1082/2200 (epoch 98.364) train_loss=614.78271484 time/batch=5.27s
1083/2200 (epoch 98.455) train_loss=1073.00476074 time/batch=11.96s
1084/2200 (epoch 98.545) train_loss=520.33038330 time/batch=15.62s
1085/2200 (epoch 98.636) train_loss=484.42425537 time/batch=4.11s
1086/2200 (epoch 98.727) train_loss=737.32647705 time/batch=6.58s
1087/2200 (epoch 98.818) train_loss=387.88607788 time/batch=4.17s
1088/2200 (epoch 98.909) train_loss=427.57748413 time/batch=5.29s
1089/2200 (epoch 99.000) train_loss=513.90454102 time/batch=14.67s
setting learning rate to 0.0002788
1090/2200 (epoch 99.091) train_loss=764.91235352 time/batch=6.59s
1091/2200 (epoch 99.182) train_loss=818.67749023 time/batch=17.67s
1092/2200 (epoch 99.273) train_loss=576.16931152 time/batch=5.10s
1093/2200 (epoch 99.364) train_loss=1161.77062988 time/batch=11.86s
1094/2200 (epoch 99.455) train_loss=383.71221924 time/batch=14.57s
1095/2200 (epoch 99.545) train_loss=886.66528320 time/batch=7.80s
1096/2200 (epoch 99.636) train_loss=400.33068848 time/batch=3.28s
1097/2200 (epoch 99.727) train_loss=888.14794922 time/batch=8.37s
1098/2200 (epoch 99.818) train_loss=503.20266724 time/batch=3.97s
1099/2200 (epoch 99.909) train_loss=443.72073364 time/batch=15.36s
1100/2200 (epoch 100.000) train_loss=728.93499756 time/batch=8.77s
setting learning rate to 0.0002705
  saved to metadata/configSample--20250116-172737.pkl
1101/2200 (epoch 100.091) train_loss=1094.33508301 time/batch=9.50s
1102/2200 (epoch 100.182) train_loss=1154.25341797 time/batch=11.00s
1103/2200 (epoch 100.273) train_loss=341.71905518 time/batch=3.03s
1104/2200 (epoch 100.364) train_loss=541.15386963 time/batch=4.69s
1105/2200 (epoch 100.455) train_loss=880.32879639 time/batch=11.73s
1106/2200 (epoch 100.545) train_loss=523.94293213 time/batch=5.06s
1107/2200 (epoch 100.636) train_loss=405.33334351 time/batch=3.52s
1108/2200 (epoch 100.727) train_loss=787.07360840 time/batch=6.58s
1109/2200 (epoch 100.818) train_loss=487.72979736 time/batch=15.52s
1110/2200 (epoch 100.909) train_loss=666.72058105 time/batch=24.64s
1111/2200 (epoch 101.000) train_loss=766.00720215 time/batch=17.46s
setting learning rate to 0.0002623
1112/2200 (epoch 101.091) train_loss=778.52313232 time/batch=17.49s
1113/2200 (epoch 101.182) train_loss=1154.29858398 time/batch=11.84s
1114/2200 (epoch 101.273) train_loss=481.45117188 time/batch=3.99s
1115/2200 (epoch 101.364) train_loss=1037.07751465 time/batch=8.88s
1116/2200 (epoch 101.455) train_loss=347.47561646 time/batch=3.15s
1117/2200 (epoch 101.545) train_loss=465.91372681 time/batch=15.68s
1118/2200 (epoch 101.636) train_loss=354.23095703 time/batch=14.45s
1119/2200 (epoch 101.727) train_loss=625.87634277 time/batch=5.22s
1120/2200 (epoch 101.818) train_loss=781.94482422 time/batch=6.63s
1121/2200 (epoch 101.909) train_loss=864.06854248 time/batch=7.46s
1122/2200 (epoch 102.000) train_loss=673.00476074 time/batch=24.54s
setting learning rate to 0.0002545
1123/2200 (epoch 102.091) train_loss=765.14825439 time/batch=6.61s
1124/2200 (epoch 102.182) train_loss=912.15625000 time/batch=8.11s
1125/2200 (epoch 102.273) train_loss=1166.94531250 time/batch=10.78s
1126/2200 (epoch 102.364) train_loss=780.13928223 time/batch=17.48s
1127/2200 (epoch 102.455) train_loss=662.40417480 time/batch=5.49s
1128/2200 (epoch 102.545) train_loss=520.49218750 time/batch=4.67s
1129/2200 (epoch 102.636) train_loss=997.57135010 time/batch=11.80s
1130/2200 (epoch 102.727) train_loss=608.40600586 time/batch=24.73s
1131/2200 (epoch 102.818) train_loss=362.98919678 time/batch=3.24s
1132/2200 (epoch 102.909) train_loss=469.44424438 time/batch=3.96s
1133/2200 (epoch 103.000) train_loss=502.61602783 time/batch=15.53s
setting learning rate to 0.0002468
1134/2200 (epoch 103.091) train_loss=883.09265137 time/batch=7.85s
1135/2200 (epoch 103.182) train_loss=461.58526611 time/batch=15.39s
1136/2200 (epoch 103.273) train_loss=582.53234863 time/batch=24.40s
1137/2200 (epoch 103.364) train_loss=864.72125244 time/batch=8.20s
1138/2200 (epoch 103.455) train_loss=740.47076416 time/batch=17.62s
1139/2200 (epoch 103.545) train_loss=1206.67785645 time/batch=11.97s
1140/2200 (epoch 103.636) train_loss=541.42987061 time/batch=4.75s
1141/2200 (epoch 103.727) train_loss=450.44677734 time/batch=3.92s
1142/2200 (epoch 103.818) train_loss=929.75762939 time/batch=8.87s
1143/2200 (epoch 103.909) train_loss=597.08013916 time/batch=5.21s
1144/2200 (epoch 104.000) train_loss=329.65869141 time/batch=2.95s
setting learning rate to 0.0002394
1145/2200 (epoch 104.091) train_loss=1151.02392578 time/batch=11.77s
1146/2200 (epoch 104.182) train_loss=724.04675293 time/batch=17.58s
1147/2200 (epoch 104.273) train_loss=496.14132690 time/batch=4.28s
1148/2200 (epoch 104.364) train_loss=814.23150635 time/batch=7.34s
1149/2200 (epoch 104.455) train_loss=816.75732422 time/batch=7.36s
1150/2200 (epoch 104.545) train_loss=336.36798096 time/batch=3.05s
1151/2200 (epoch 104.636) train_loss=613.61120605 time/batch=24.72s
1152/2200 (epoch 104.727) train_loss=1029.81164551 time/batch=8.87s
1153/2200 (epoch 104.818) train_loss=379.35845947 time/batch=3.44s
1154/2200 (epoch 104.909) train_loss=494.23599243 time/batch=15.50s
1155/2200 (epoch 105.000) train_loss=660.95837402 time/batch=7.42s
setting learning rate to 0.0002322
1156/2200 (epoch 105.091) train_loss=355.27593994 time/batch=14.58s
1157/2200 (epoch 105.182) train_loss=717.05047607 time/batch=17.65s
1158/2200 (epoch 105.273) train_loss=806.79461670 time/batch=6.53s
1159/2200 (epoch 105.364) train_loss=586.68371582 time/batch=4.80s
1160/2200 (epoch 105.455) train_loss=1058.18750000 time/batch=8.58s
1161/2200 (epoch 105.545) train_loss=489.62063599 time/batch=15.42s
1162/2200 (epoch 105.636) train_loss=699.93786621 time/batch=6.66s
1163/2200 (epoch 105.727) train_loss=557.71679688 time/batch=24.38s
1164/2200 (epoch 105.818) train_loss=995.40649414 time/batch=9.60s
1165/2200 (epoch 105.909) train_loss=525.97174072 time/batch=6.70s
1166/2200 (epoch 106.000) train_loss=982.91796875 time/batch=11.87s
setting learning rate to 0.0002253
1167/2200 (epoch 106.091) train_loss=917.25683594 time/batch=7.72s
1168/2200 (epoch 106.182) train_loss=503.71966553 time/batch=4.38s
1169/2200 (epoch 106.273) train_loss=1032.57385254 time/batch=8.96s
1170/2200 (epoch 106.364) train_loss=1130.46374512 time/batch=11.78s
1171/2200 (epoch 106.455) train_loss=332.93191528 time/batch=2.96s
1172/2200 (epoch 106.545) train_loss=596.89538574 time/batch=5.12s
1173/2200 (epoch 106.636) train_loss=473.36987305 time/batch=15.36s
1174/2200 (epoch 106.727) train_loss=721.44543457 time/batch=17.45s
1175/2200 (epoch 106.818) train_loss=413.39465332 time/batch=5.63s
1176/2200 (epoch 106.909) train_loss=778.16522217 time/batch=6.61s
1177/2200 (epoch 107.000) train_loss=578.65252686 time/batch=14.57s
setting learning rate to 0.0002185
1178/2200 (epoch 107.091) train_loss=530.21343994 time/batch=4.79s
1179/2200 (epoch 107.182) train_loss=1079.30383301 time/batch=9.74s
1180/2200 (epoch 107.273) train_loss=597.19775391 time/batch=24.66s
1181/2200 (epoch 107.364) train_loss=757.90545654 time/batch=17.72s
1182/2200 (epoch 107.455) train_loss=946.24499512 time/batch=8.15s
1183/2200 (epoch 107.545) train_loss=328.77243042 time/batch=2.96s
1184/2200 (epoch 107.636) train_loss=826.02038574 time/batch=9.85s
1185/2200 (epoch 107.727) train_loss=389.28698730 time/batch=3.46s
1186/2200 (epoch 107.818) train_loss=711.23107910 time/batch=6.55s
1187/2200 (epoch 107.909) train_loss=905.11254883 time/batch=11.88s
1188/2200 (epoch 108.000) train_loss=500.56414795 time/batch=15.60s
setting learning rate to 0.0002120
1189/2200 (epoch 108.091) train_loss=1107.30493164 time/batch=10.21s
1190/2200 (epoch 108.182) train_loss=471.87448120 time/batch=15.54s
1191/2200 (epoch 108.273) train_loss=714.88317871 time/batch=6.38s
1192/2200 (epoch 108.364) train_loss=1051.34338379 time/batch=11.88s
1193/2200 (epoch 108.455) train_loss=525.11163330 time/batch=4.72s
1194/2200 (epoch 108.545) train_loss=524.19653320 time/batch=5.11s
1195/2200 (epoch 108.636) train_loss=638.02996826 time/batch=5.53s
1196/2200 (epoch 108.727) train_loss=342.48202515 time/batch=3.15s
1197/2200 (epoch 108.818) train_loss=817.70184326 time/batch=17.68s
1198/2200 (epoch 108.909) train_loss=553.85980225 time/batch=24.79s
1199/2200 (epoch 109.000) train_loss=787.55572510 time/batch=7.55s
setting learning rate to 0.0002056
1200/2200 (epoch 109.091) train_loss=812.52844238 time/batch=7.45s
1201/2200 (epoch 109.182) train_loss=1134.63208008 time/batch=11.94s
1202/2200 (epoch 109.273) train_loss=625.49694824 time/batch=5.18s
1203/2200 (epoch 109.364) train_loss=780.79791260 time/batch=6.59s
1204/2200 (epoch 109.455) train_loss=1019.61108398 time/batch=8.93s
1205/2200 (epoch 109.545) train_loss=367.06185913 time/batch=14.61s
1206/2200 (epoch 109.636) train_loss=357.93875122 time/batch=3.10s
1207/2200 (epoch 109.727) train_loss=494.50369263 time/batch=4.16s
1208/2200 (epoch 109.818) train_loss=705.54907227 time/batch=17.60s
1209/2200 (epoch 109.909) train_loss=630.85424805 time/batch=7.55s
1210/2200 (epoch 110.000) train_loss=610.34320068 time/batch=24.53s
setting learning rate to 0.0001994
  saved to metadata/configSample--20250116-172737.pkl
1211/2200 (epoch 110.091) train_loss=386.37814331 time/batch=3.51s
1212/2200 (epoch 110.182) train_loss=723.08465576 time/batch=6.45s
1213/2200 (epoch 110.273) train_loss=737.88793945 time/batch=17.74s
1214/2200 (epoch 110.364) train_loss=1108.99108887 time/batch=11.91s
1215/2200 (epoch 110.455) train_loss=589.07189941 time/batch=24.64s
1216/2200 (epoch 110.545) train_loss=398.92514038 time/batch=15.59s
1217/2200 (epoch 110.636) train_loss=484.43078613 time/batch=4.20s
1218/2200 (epoch 110.727) train_loss=525.56201172 time/batch=4.85s
1219/2200 (epoch 110.818) train_loss=646.29663086 time/batch=6.63s
1220/2200 (epoch 110.909) train_loss=1053.92395020 time/batch=8.94s
1221/2200 (epoch 111.000) train_loss=885.32916260 time/batch=7.54s
setting learning rate to 0.0001935
1222/2200 (epoch 111.091) train_loss=617.33660889 time/batch=5.19s
1223/2200 (epoch 111.182) train_loss=1095.91333008 time/batch=10.31s
1224/2200 (epoch 111.273) train_loss=819.98309326 time/batch=7.47s
1225/2200 (epoch 111.364) train_loss=1031.02111816 time/batch=11.84s
1226/2200 (epoch 111.455) train_loss=379.76907349 time/batch=3.34s
1227/2200 (epoch 111.545) train_loss=743.28576660 time/batch=17.46s
1228/2200 (epoch 111.636) train_loss=506.88796997 time/batch=5.25s
1229/2200 (epoch 111.727) train_loss=341.29626465 time/batch=3.48s
1230/2200 (epoch 111.818) train_loss=429.57388306 time/batch=15.56s
1231/2200 (epoch 111.909) train_loss=579.77728271 time/batch=6.22s
1232/2200 (epoch 112.000) train_loss=704.46386719 time/batch=24.60s
setting learning rate to 0.0001877
1233/2200 (epoch 112.091) train_loss=928.24713135 time/batch=8.11s
1234/2200 (epoch 112.182) train_loss=785.26739502 time/batch=17.54s
1235/2200 (epoch 112.273) train_loss=586.70324707 time/batch=24.45s
1236/2200 (epoch 112.364) train_loss=1122.33081055 time/batch=11.03s
1237/2200 (epoch 112.455) train_loss=451.05181885 time/batch=15.47s
1238/2200 (epoch 112.545) train_loss=336.15704346 time/batch=3.55s
1239/2200 (epoch 112.636) train_loss=584.10638428 time/batch=5.14s
1240/2200 (epoch 112.727) train_loss=607.68066406 time/batch=5.55s
1241/2200 (epoch 112.818) train_loss=635.51916504 time/batch=6.60s
1242/2200 (epoch 112.909) train_loss=690.59185791 time/batch=6.77s
1243/2200 (epoch 113.000) train_loss=796.48419189 time/batch=11.84s
setting learning rate to 0.0001820
1244/2200 (epoch 113.091) train_loss=389.23742676 time/batch=3.52s
1245/2200 (epoch 113.182) train_loss=363.50332642 time/batch=14.45s
1246/2200 (epoch 113.273) train_loss=526.84747314 time/batch=24.72s
1247/2200 (epoch 113.364) train_loss=463.84689331 time/batch=4.01s
1248/2200 (epoch 113.455) train_loss=796.82421875 time/batch=7.25s
1249/2200 (epoch 113.545) train_loss=640.13110352 time/batch=5.43s
1250/2200 (epoch 113.636) train_loss=511.87768555 time/batch=15.40s
1251/2200 (epoch 113.727) train_loss=982.44964600 time/batch=8.85s
1252/2200 (epoch 113.818) train_loss=1049.24597168 time/batch=10.06s
1253/2200 (epoch 113.909) train_loss=741.50537109 time/batch=6.55s
1254/2200 (epoch 114.000) train_loss=877.48101807 time/batch=17.70s
setting learning rate to 0.0001766
1255/2200 (epoch 114.091) train_loss=573.95098877 time/batch=5.10s
1256/2200 (epoch 114.182) train_loss=1008.40545654 time/batch=9.24s
1257/2200 (epoch 114.273) train_loss=1105.04858398 time/batch=11.92s
1258/2200 (epoch 114.364) train_loss=678.33551025 time/batch=17.56s
1259/2200 (epoch 114.455) train_loss=368.80886841 time/batch=14.61s
1260/2200 (epoch 114.545) train_loss=797.18005371 time/batch=7.46s
1261/2200 (epoch 114.636) train_loss=713.32904053 time/batch=6.50s
1262/2200 (epoch 114.727) train_loss=432.06283569 time/batch=15.57s
1263/2200 (epoch 114.818) train_loss=458.30108643 time/batch=4.11s
1264/2200 (epoch 114.909) train_loss=520.25854492 time/batch=6.54s
1265/2200 (epoch 115.000) train_loss=524.14892578 time/batch=24.45s
setting learning rate to 0.0001713
1266/2200 (epoch 115.091) train_loss=381.29632568 time/batch=3.52s
1267/2200 (epoch 115.182) train_loss=356.23892212 time/batch=14.45s
1268/2200 (epoch 115.273) train_loss=1063.91418457 time/batch=10.64s
1269/2200 (epoch 115.364) train_loss=853.57861328 time/batch=7.43s
1270/2200 (epoch 115.455) train_loss=767.62933350 time/batch=17.44s
1271/2200 (epoch 115.545) train_loss=482.02859497 time/batch=4.27s
1272/2200 (epoch 115.636) train_loss=987.00103760 time/batch=11.85s
1273/2200 (epoch 115.727) train_loss=345.19171143 time/batch=15.27s
1274/2200 (epoch 115.818) train_loss=463.10647583 time/batch=13.15s
1275/2200 (epoch 115.909) train_loss=630.48303223 time/batch=6.25s
1276/2200 (epoch 116.000) train_loss=671.39898682 time/batch=6.58s
setting learning rate to 0.0001661
1277/2200 (epoch 116.091) train_loss=561.62622070 time/batch=5.21s
1278/2200 (epoch 116.182) train_loss=1027.79614258 time/batch=9.66s
1279/2200 (epoch 116.273) train_loss=581.04968262 time/batch=24.64s
1280/2200 (epoch 116.364) train_loss=805.97595215 time/batch=7.47s
1281/2200 (epoch 116.455) train_loss=1051.90795898 time/batch=11.95s
1282/2200 (epoch 116.545) train_loss=344.63290405 time/batch=3.24s
1283/2200 (epoch 116.636) train_loss=362.01159668 time/batch=3.53s
1284/2200 (epoch 116.727) train_loss=716.22027588 time/batch=17.61s
1285/2200 (epoch 116.818) train_loss=606.91851807 time/batch=6.08s
1286/2200 (epoch 116.909) train_loss=699.33245850 time/batch=6.67s
1287/2200 (epoch 117.000) train_loss=469.19436646 time/batch=15.52s
setting learning rate to 0.0001611
1288/2200 (epoch 117.091) train_loss=476.48168945 time/batch=4.52s
1289/2200 (epoch 117.182) train_loss=309.58398438 time/batch=2.93s
1290/2200 (epoch 117.273) train_loss=973.00720215 time/batch=9.24s
1291/2200 (epoch 117.364) train_loss=781.25469971 time/batch=7.21s
1292/2200 (epoch 117.455) train_loss=648.61285400 time/batch=5.53s
1293/2200 (epoch 117.545) train_loss=767.80499268 time/batch=7.49s
1294/2200 (epoch 117.636) train_loss=1051.58520508 time/batch=11.99s
1295/2200 (epoch 117.727) train_loss=709.30792236 time/batch=17.58s
1296/2200 (epoch 117.818) train_loss=388.32647705 time/batch=14.55s
1297/2200 (epoch 117.909) train_loss=548.00708008 time/batch=24.72s
1298/2200 (epoch 118.000) train_loss=462.51327515 time/batch=4.67s
setting learning rate to 0.0001563
1299/2200 (epoch 118.091) train_loss=733.97521973 time/batch=6.79s
1300/2200 (epoch 118.182) train_loss=908.31060791 time/batch=8.70s
1301/2200 (epoch 118.273) train_loss=573.51177979 time/batch=5.13s
1302/2200 (epoch 118.364) train_loss=811.60113525 time/batch=8.90s
1303/2200 (epoch 118.455) train_loss=837.47241211 time/batch=9.59s
1304/2200 (epoch 118.545) train_loss=324.91592407 time/batch=3.08s
1305/2200 (epoch 118.636) train_loss=344.19476318 time/batch=3.38s
1306/2200 (epoch 118.727) train_loss=416.65875244 time/batch=15.56s
1307/2200 (epoch 118.818) train_loss=605.70471191 time/batch=24.72s
1308/2200 (epoch 118.909) train_loss=826.45196533 time/batch=17.64s
1309/2200 (epoch 119.000) train_loss=703.93920898 time/batch=11.86s
setting learning rate to 0.0001516
1310/2200 (epoch 119.091) train_loss=464.21823120 time/batch=4.22s
1311/2200 (epoch 119.182) train_loss=597.45068359 time/batch=5.59s
1312/2200 (epoch 119.273) train_loss=440.85000610 time/batch=15.55s
1313/2200 (epoch 119.364) train_loss=742.03204346 time/batch=6.79s
1314/2200 (epoch 119.455) train_loss=946.40673828 time/batch=8.31s
1315/2200 (epoch 119.545) train_loss=334.43325806 time/batch=2.96s
1316/2200 (epoch 119.636) train_loss=690.20678711 time/batch=17.55s
1317/2200 (epoch 119.727) train_loss=376.83776855 time/batch=4.25s
1318/2200 (epoch 119.818) train_loss=685.33850098 time/batch=14.49s
1319/2200 (epoch 119.909) train_loss=487.43383789 time/batch=7.15s
1320/2200 (epoch 120.000) train_loss=1018.10980225 time/batch=9.93s
setting learning rate to 0.0001471
  saved to metadata/configSample--20250116-172737.pkl
1321/2200 (epoch 120.091) train_loss=669.28643799 time/batch=17.61s
1322/2200 (epoch 120.182) train_loss=559.78619385 time/batch=24.80s
1323/2200 (epoch 120.273) train_loss=464.69140625 time/batch=15.63s
1324/2200 (epoch 120.364) train_loss=548.40118408 time/batch=5.16s
1325/2200 (epoch 120.455) train_loss=991.81500244 time/batch=10.02s
1326/2200 (epoch 120.545) train_loss=986.72546387 time/batch=11.83s
1327/2200 (epoch 120.636) train_loss=463.91458130 time/batch=4.00s
1328/2200 (epoch 120.727) train_loss=320.15423584 time/batch=2.98s
1329/2200 (epoch 120.818) train_loss=423.29080200 time/batch=5.67s
1330/2200 (epoch 120.909) train_loss=759.82916260 time/batch=7.40s
1331/2200 (epoch 121.000) train_loss=695.01129150 time/batch=6.40s
setting learning rate to 0.0001427
1332/2200 (epoch 121.091) train_loss=1034.62622070 time/batch=9.54s
1333/2200 (epoch 121.182) train_loss=751.12048340 time/batch=6.37s
1334/2200 (epoch 121.273) train_loss=364.47415161 time/batch=14.51s
1335/2200 (epoch 121.364) train_loss=532.22064209 time/batch=24.77s
1336/2200 (epoch 121.455) train_loss=517.23120117 time/batch=4.84s
1337/2200 (epoch 121.545) train_loss=791.29211426 time/batch=7.55s
1338/2200 (epoch 121.636) train_loss=370.03851318 time/batch=3.47s
1339/2200 (epoch 121.727) train_loss=447.08621216 time/batch=15.27s
1340/2200 (epoch 121.818) train_loss=724.98071289 time/batch=17.56s
1341/2200 (epoch 121.909) train_loss=985.96368408 time/batch=11.93s
1342/2200 (epoch 122.000) train_loss=587.54815674 time/batch=5.21s
setting learning rate to 0.0001384
1343/2200 (epoch 122.091) train_loss=1103.80493164 time/batch=11.85s
1344/2200 (epoch 122.182) train_loss=631.10760498 time/batch=5.49s
1345/2200 (epoch 122.273) train_loss=922.06701660 time/batch=8.82s
1346/2200 (epoch 122.364) train_loss=496.35070801 time/batch=4.70s
1347/2200 (epoch 122.455) train_loss=336.66836548 time/batch=14.53s
1348/2200 (epoch 122.545) train_loss=438.55789185 time/batch=4.68s
1349/2200 (epoch 122.636) train_loss=711.89306641 time/batch=6.75s
1350/2200 (epoch 122.727) train_loss=631.96356201 time/batch=17.49s
1351/2200 (epoch 122.818) train_loss=514.86608887 time/batch=24.46s
1352/2200 (epoch 122.909) train_loss=389.58731079 time/batch=5.75s
1353/2200 (epoch 123.000) train_loss=637.55932617 time/batch=7.01s
setting learning rate to 0.0001342
1354/2200 (epoch 123.091) train_loss=714.67266846 time/batch=6.78s
1355/2200 (epoch 123.182) train_loss=552.49291992 time/batch=5.21s
1356/2200 (epoch 123.273) train_loss=732.27337646 time/batch=7.42s
1357/2200 (epoch 123.364) train_loss=309.84848022 time/batch=2.87s
1358/2200 (epoch 123.455) train_loss=993.32995605 time/batch=9.59s
1359/2200 (epoch 123.545) train_loss=373.21188354 time/batch=14.46s
1360/2200 (epoch 123.636) train_loss=474.29638672 time/batch=4.49s
1361/2200 (epoch 123.727) train_loss=931.24157715 time/batch=10.64s
1362/2200 (epoch 123.818) train_loss=636.04833984 time/batch=17.67s
1363/2200 (epoch 123.909) train_loss=401.68963623 time/batch=15.48s
1364/2200 (epoch 124.000) train_loss=451.06420898 time/batch=13.16s
setting learning rate to 0.0001302
1365/2200 (epoch 124.091) train_loss=584.02685547 time/batch=5.56s
1366/2200 (epoch 124.182) train_loss=878.16265869 time/batch=8.74s
1367/2200 (epoch 124.273) train_loss=570.80163574 time/batch=24.36s
1368/2200 (epoch 124.364) train_loss=829.51348877 time/batch=9.13s
1369/2200 (epoch 124.455) train_loss=511.80215454 time/batch=4.80s
1370/2200 (epoch 124.545) train_loss=972.91424561 time/batch=11.76s
1371/2200 (epoch 124.636) train_loss=324.56628418 time/batch=3.18s
1372/2200 (epoch 124.727) train_loss=678.66931152 time/batch=6.58s
1373/2200 (epoch 124.818) train_loss=407.28390503 time/batch=15.25s
1374/2200 (epoch 124.909) train_loss=465.00784302 time/batch=5.07s
1375/2200 (epoch 125.000) train_loss=451.46853638 time/batch=17.49s
setting learning rate to 0.0001263
1376/2200 (epoch 125.091) train_loss=652.67974854 time/batch=6.45s
1377/2200 (epoch 125.182) train_loss=954.09973145 time/batch=9.37s
1378/2200 (epoch 125.273) train_loss=368.42379761 time/batch=14.45s
1379/2200 (epoch 125.364) train_loss=721.26538086 time/batch=6.76s
1380/2200 (epoch 125.455) train_loss=479.18176270 time/batch=4.36s
1381/2200 (epoch 125.545) train_loss=1382.57141113 time/batch=11.83s
1382/2200 (epoch 125.636) train_loss=651.77178955 time/batch=5.56s
1383/2200 (epoch 125.727) train_loss=298.60852051 time/batch=3.03s
1384/2200 (epoch 125.818) train_loss=350.70599365 time/batch=3.51s
1385/2200 (epoch 125.909) train_loss=724.77905273 time/batch=17.38s
1386/2200 (epoch 126.000) train_loss=664.11535645 time/batch=24.44s
setting learning rate to 0.0001225
1387/2200 (epoch 126.091) train_loss=893.72192383 time/batch=8.96s
1388/2200 (epoch 126.182) train_loss=489.12731934 time/batch=4.68s
1389/2200 (epoch 126.273) train_loss=338.17858887 time/batch=14.44s
1390/2200 (epoch 126.364) train_loss=718.28802490 time/batch=7.17s
1391/2200 (epoch 126.455) train_loss=296.52093506 time/batch=3.07s
1392/2200 (epoch 126.545) train_loss=769.93780518 time/batch=9.37s
1393/2200 (epoch 126.636) train_loss=564.65972900 time/batch=5.50s
1394/2200 (epoch 126.727) train_loss=701.49468994 time/batch=17.50s
1395/2200 (epoch 126.818) train_loss=762.22064209 time/batch=10.07s
1396/2200 (epoch 126.909) train_loss=345.34970093 time/batch=3.49s
1397/2200 (epoch 127.000) train_loss=491.17272949 time/batch=10.66s
setting learning rate to 0.0001188
1398/2200 (epoch 127.091) train_loss=634.53021240 time/batch=17.46s
1399/2200 (epoch 127.182) train_loss=464.69519043 time/batch=4.36s
1400/2200 (epoch 127.273) train_loss=429.24523926 time/batch=15.38s
1401/2200 (epoch 127.364) train_loss=627.42822266 time/batch=6.31s
1402/2200 (epoch 127.455) train_loss=991.58111572 time/batch=11.74s
1403/2200 (epoch 127.545) train_loss=874.90399170 time/batch=8.69s
1404/2200 (epoch 127.636) train_loss=582.08776855 time/batch=6.34s
1405/2200 (epoch 127.727) train_loss=511.38815308 time/batch=6.58s
1406/2200 (epoch 127.818) train_loss=745.44042969 time/batch=8.89s
1407/2200 (epoch 127.909) train_loss=339.82849121 time/batch=14.51s
1408/2200 (epoch 128.000) train_loss=282.97909546 time/batch=3.04s
setting learning rate to 0.0001153
1409/2200 (epoch 128.091) train_loss=640.62677002 time/batch=17.55s
1410/2200 (epoch 128.182) train_loss=526.22985840 time/batch=24.36s
1411/2200 (epoch 128.273) train_loss=789.72784424 time/batch=7.99s
1412/2200 (epoch 128.364) train_loss=416.85650635 time/batch=3.90s
1413/2200 (epoch 128.455) train_loss=475.67782593 time/batch=4.54s
1414/2200 (epoch 128.545) train_loss=1003.88250732 time/batch=11.59s
1415/2200 (epoch 128.636) train_loss=677.85931396 time/batch=6.32s
1416/2200 (epoch 128.727) train_loss=575.99182129 time/batch=6.44s
1417/2200 (epoch 128.818) train_loss=801.56628418 time/batch=8.63s
1418/2200 (epoch 128.909) train_loss=511.42196655 time/batch=15.10s
1419/2200 (epoch 129.000) train_loss=305.94985962 time/batch=3.15s
setting learning rate to 0.0001118
1420/2200 (epoch 129.091) train_loss=333.56677246 time/batch=3.40s
1421/2200 (epoch 129.182) train_loss=536.79034424 time/batch=5.34s
1422/2200 (epoch 129.273) train_loss=428.77435303 time/batch=4.08s
1423/2200 (epoch 129.364) train_loss=979.83453369 time/batch=11.50s
1424/2200 (epoch 129.455) train_loss=852.09698486 time/batch=9.03s
1425/2200 (epoch 129.545) train_loss=508.02410889 time/batch=5.36s
1426/2200 (epoch 129.636) train_loss=397.69992065 time/batch=14.89s
1427/2200 (epoch 129.727) train_loss=524.71685791 time/batch=24.34s
1428/2200 (epoch 129.818) train_loss=630.50189209 time/batch=6.18s
1429/2200 (epoch 129.909) train_loss=723.90594482 time/batch=7.20s
1430/2200 (epoch 130.000) train_loss=486.41192627 time/batch=17.44s
setting learning rate to 0.0001085
  saved to metadata/configSample--20250116-172737.pkl
1431/2200 (epoch 130.091) train_loss=513.81457520 time/batch=24.54s
1432/2200 (epoch 130.182) train_loss=693.01055908 time/batch=7.22s
1433/2200 (epoch 130.273) train_loss=884.82690430 time/batch=9.20s
1434/2200 (epoch 130.364) train_loss=587.15093994 time/batch=5.36s
1435/2200 (epoch 130.455) train_loss=545.46362305 time/batch=5.61s
1436/2200 (epoch 130.545) train_loss=987.14672852 time/batch=11.12s
1437/2200 (epoch 130.636) train_loss=774.17712402 time/batch=11.99s
1438/2200 (epoch 130.727) train_loss=646.47259521 time/batch=17.80s
1439/2200 (epoch 130.818) train_loss=289.73370361 time/batch=2.99s
1440/2200 (epoch 130.909) train_loss=421.84054565 time/batch=15.74s
1441/2200 (epoch 131.000) train_loss=389.67874146 time/batch=4.05s
setting learning rate to 0.0001052
1442/2200 (epoch 131.091) train_loss=512.65948486 time/batch=24.41s
1443/2200 (epoch 131.182) train_loss=621.71374512 time/batch=6.80s
1444/2200 (epoch 131.273) train_loss=482.00531006 time/batch=5.19s
1445/2200 (epoch 131.364) train_loss=505.29544067 time/batch=5.07s
1446/2200 (epoch 131.455) train_loss=832.32281494 time/batch=8.37s
1447/2200 (epoch 131.545) train_loss=846.83666992 time/batch=12.54s
1448/2200 (epoch 131.636) train_loss=593.68670654 time/batch=37.89s
1449/2200 (epoch 131.727) train_loss=425.60626221 time/batch=33.44s
1450/2200 (epoch 131.818) train_loss=844.27722168 time/batch=25.69s
1451/2200 (epoch 131.909) train_loss=526.86932373 time/batch=14.24s
1452/2200 (epoch 132.000) train_loss=288.10491943 time/batch=6.47s
setting learning rate to 0.0001020
1453/2200 (epoch 132.091) train_loss=650.11364746 time/batch=37.65s
1454/2200 (epoch 132.182) train_loss=551.34710693 time/batch=11.95s
1455/2200 (epoch 132.273) train_loss=959.36724854 time/batch=25.65s
1456/2200 (epoch 132.364) train_loss=359.63519287 time/batch=7.42s
1457/2200 (epoch 132.455) train_loss=578.66534424 time/batch=14.06s
1458/2200 (epoch 132.545) train_loss=313.58926392 time/batch=31.48s
1459/2200 (epoch 132.636) train_loss=372.30496216 time/batch=33.39s
1460/2200 (epoch 132.727) train_loss=593.40155029 time/batch=14.61s
1461/2200 (epoch 132.818) train_loss=421.66848755 time/batch=8.75s
1462/2200 (epoch 132.909) train_loss=827.72003174 time/batch=19.12s
1463/2200 (epoch 133.000) train_loss=549.75274658 time/batch=15.50s
setting learning rate to 0.0000990
1464/2200 (epoch 133.091) train_loss=297.48379517 time/batch=6.61s
1465/2200 (epoch 133.182) train_loss=645.60028076 time/batch=37.64s
1466/2200 (epoch 133.273) train_loss=333.23019409 time/batch=31.45s
1467/2200 (epoch 133.364) train_loss=533.83801270 time/batch=11.77s
1468/2200 (epoch 133.455) train_loss=860.15393066 time/batch=20.56s
1469/2200 (epoch 133.545) train_loss=935.99914551 time/batch=25.68s
1470/2200 (epoch 133.636) train_loss=743.37579346 time/batch=14.47s
1471/2200 (epoch 133.727) train_loss=433.20617676 time/batch=8.50s
1472/2200 (epoch 133.818) train_loss=434.84628296 time/batch=33.30s
1473/2200 (epoch 133.909) train_loss=456.91830444 time/batch=10.39s
1474/2200 (epoch 134.000) train_loss=647.08563232 time/batch=52.70s
setting learning rate to 0.0000960
1475/2200 (epoch 134.091) train_loss=668.13037109 time/batch=14.67s
1476/2200 (epoch 134.182) train_loss=872.78588867 time/batch=19.37s
1477/2200 (epoch 134.273) train_loss=1078.87719727 time/batch=25.60s
1478/2200 (epoch 134.364) train_loss=688.77160645 time/batch=37.90s
1479/2200 (epoch 134.455) train_loss=664.26513672 time/batch=16.01s
1480/2200 (epoch 134.545) train_loss=285.49871826 time/batch=6.36s
1481/2200 (epoch 134.636) train_loss=335.85525513 time/batch=31.31s
1482/2200 (epoch 134.727) train_loss=481.51849365 time/batch=10.98s
1483/2200 (epoch 134.818) train_loss=306.10916138 time/batch=7.52s
1484/2200 (epoch 134.909) train_loss=417.01498413 time/batch=8.73s
1485/2200 (epoch 135.000) train_loss=509.98120117 time/batch=16.09s
setting learning rate to 0.0000931
1486/2200 (epoch 135.091) train_loss=934.26593018 time/batch=25.68s
1487/2200 (epoch 135.182) train_loss=659.67675781 time/batch=37.67s
1488/2200 (epoch 135.273) train_loss=411.74237061 time/batch=33.43s
1489/2200 (epoch 135.364) train_loss=414.12811279 time/batch=8.78s
1490/2200 (epoch 135.455) train_loss=526.37628174 time/batch=11.79s
1491/2200 (epoch 135.545) train_loss=429.00210571 time/batch=10.18s
1492/2200 (epoch 135.636) train_loss=277.11053467 time/batch=6.35s
1493/2200 (epoch 135.727) train_loss=660.40185547 time/batch=15.37s
1494/2200 (epoch 135.818) train_loss=655.60864258 time/batch=16.40s
1495/2200 (epoch 135.909) train_loss=506.30487061 time/batch=52.54s
1496/2200 (epoch 136.000) train_loss=533.64807129 time/batch=17.40s
setting learning rate to 0.0000903
1497/2200 (epoch 136.091) train_loss=636.26885986 time/batch=14.12s
1498/2200 (epoch 136.182) train_loss=535.10845947 time/batch=11.36s
1499/2200 (epoch 136.273) train_loss=427.30673218 time/batch=33.22s
Validating
    loss:	1097.151733

1500/2200 (epoch 136.364) train_loss=585.37512207 time/batch=173.32s
1501/2200 (epoch 136.455) train_loss=836.76031494 time/batch=20.06s
1502/2200 (epoch 136.545) train_loss=280.97613525 time/batch=6.34s
1503/2200 (epoch 136.636) train_loss=618.06939697 time/batch=14.75s
1504/2200 (epoch 136.727) train_loss=800.80249023 time/batch=21.31s
1505/2200 (epoch 136.818) train_loss=469.00195312 time/batch=14.91s
1506/2200 (epoch 136.909) train_loss=524.35021973 time/batch=21.99s
1507/2200 (epoch 137.000) train_loss=456.40560913 time/batch=31.23s
setting learning rate to 0.0000876
1508/2200 (epoch 137.091) train_loss=286.15509033 time/batch=6.57s
1509/2200 (epoch 137.182) train_loss=599.08441162 time/batch=13.90s
1510/2200 (epoch 137.273) train_loss=444.57833862 time/batch=9.92s
1511/2200 (epoch 137.364) train_loss=860.71722412 time/batch=20.78s
1512/2200 (epoch 137.455) train_loss=502.00299072 time/batch=52.39s
1513/2200 (epoch 137.545) train_loss=833.78833008 time/batch=22.57s
1514/2200 (epoch 137.636) train_loss=519.18371582 time/batch=11.21s
1515/2200 (epoch 137.727) train_loss=413.62210083 time/batch=33.08s
1516/2200 (epoch 137.818) train_loss=721.22253418 time/batch=25.50s
1517/2200 (epoch 137.909) train_loss=326.89782715 time/batch=8.26s
1518/2200 (epoch 138.000) train_loss=639.80609131 time/batch=37.65s
setting learning rate to 0.0000850
1519/2200 (epoch 138.091) train_loss=633.99877930 time/batch=14.59s
1520/2200 (epoch 138.182) train_loss=649.86566162 time/batch=15.39s
1521/2200 (epoch 138.273) train_loss=762.77514648 time/batch=17.45s
1522/2200 (epoch 138.364) train_loss=290.21408081 time/batch=6.72s
1523/2200 (epoch 138.455) train_loss=419.40841675 time/batch=33.25s
1524/2200 (epoch 