{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca523df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa19822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# Configurations (modify as needed)\n",
    "class Config:\n",
    "    validation_fraction = 0.2  # Fraction of data used for validation\n",
    "    batch_size = 32  # Batch size\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Define data path\n",
    "data_path = 'data/data_v2'\n",
    "assert os.path.exists(data_path), \"Data path does not exist!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc710d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data from the specified path\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Split the data into tokens and initialize the token set\n",
    "tokens_set = set(data.split())\n",
    "start_symbol, end_symbol = '<s>', '</s>'\n",
    "tokens_set.update({start_symbol, end_symbol})\n",
    "\n",
    "# Create vocabulary mappings\n",
    "idx2token = list(tokens_set)\n",
    "vocab_size = len(idx2token)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "token2idx = dict(izip(idx2token, range(vocab_size)))  # Use zip for Python 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the tunes and tokenize them\n",
    "tunes = data.split('\\n\\n')\n",
    "del data  # Free up memory\n",
    "\n",
    "tunes = [\n",
    "    [token2idx[c] for c in [start_symbol] + t.split() + [end_symbol]]\n",
    "    for t in tunes\n",
    "]\n",
    "\n",
    "# Sort tunes by length (longest first)\n",
    "tunes.sort(key=lambda x: len(x), reverse=True)\n",
    "ntunes = len(tunes)\n",
    "print('Number of tunes:', ntunes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f0b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tunes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa70359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate tune lengths\n",
    "tune_lens = np.array([len(t) for t in tunes])\n",
    "max_len = max(tune_lens)\n",
    "print('Max tune length:', max_len)\n",
    "\n",
    "# Calculate the number of validation tunes\n",
    "nvalid_tunes = ntunes * config.validation_fraction\n",
    "nvalid_tunes = config.batch_size * max(\n",
    "    1, int(round(nvalid_tunes / float(config.batch_size)))\n",
    ")  # Round to a multiple of batch_size\n",
    "print('Number of validation tunes:', nvalid_tunes)\n",
    "\n",
    "# Split into training and validation sets\n",
    "rng = np.random.RandomState(42)  # Fixed seed for reproducibility\n",
    "valid_idxs = rng.choice(np.arange(ntunes), int(nvalid_tunes), replace=False)\n",
    "\n",
    "# Create validation and training datasets\n",
    "valid_tunes = [tunes[i] for i in valid_idxs]\n",
    "train_tunes = [tunes[i] for i in range(ntunes) if i not in valid_idxs]\n",
    "\n",
    "print('Training tunes:', len(train_tunes))\n",
    "print('Validation tunes:', len(valid_tunes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'DutchFolkTunes/dataset.txt'\n",
    "assert os.path.exists(data_path), \"Data path does not exist!\"\n",
    "\n",
    "\n",
    "# Load data from the specified path\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Split the data into tokens and initialize the token set\n",
    "tokens_set = set(data.split())\n",
    "start_symbol, end_symbol = '<s>', '</s>'\n",
    "tokens_set.update({start_symbol, end_symbol})\n",
    "\n",
    "# Create vocabulary mappings\n",
    "idx2token = list(tokens_set)\n",
    "vocab_size = len(idx2token)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "token2idx = dict(izip(idx2token, range(vocab_size)))  # Use zip for Python 3\n",
    "\n",
    "# Process the tunes and tokenize them\n",
    "tunes = data.split('\\n\\n')\n",
    "del data  # Free up memory\n",
    "\n",
    "tunes = [\n",
    "    [token2idx[c] for c in [start_symbol] + t.split() + [end_symbol]]\n",
    "    for t in tunes\n",
    "]\n",
    "\n",
    "# Sort tunes by length (longest first)\n",
    "tunes.sort(key=lambda x: len(x), reverse=True)\n",
    "ntunes = len(tunes)\n",
    "print('Number of tunes:', ntunes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a07236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tune lengths\n",
    "tune_lens = np.array([len(t) for t in tunes])\n",
    "max_len = max(tune_lens)\n",
    "print('Max tune length:', max_len)\n",
    "\n",
    "# Calculate the number of validation tunes\n",
    "nvalid_tunes = ntunes * config.validation_fraction\n",
    "nvalid_tunes = config.batch_size * max(\n",
    "    1, int(round(nvalid_tunes / float(config.batch_size)))\n",
    ")  # Round to a multiple of batch_size\n",
    "print('Number of validation tunes:', nvalid_tunes)\n",
    "\n",
    "# Split into training and validation sets\n",
    "rng = np.random.RandomState(42)  # Fixed seed for reproducibility\n",
    "valid_idxs = rng.choice(np.arange(ntunes), int(nvalid_tunes), replace=False)\n",
    "\n",
    "# Create validation and training datasets\n",
    "valid_tunes = [tunes[i] for i in valid_idxs]\n",
    "train_tunes = [tunes[i] for i in range(ntunes) if i not in valid_idxs]\n",
    "\n",
    "print('Training tunes:', len(train_tunes))\n",
    "print('Validation tunes:', len(valid_tunes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set up plot styles\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Prepare a pandas DataFrame for tune lengths\n",
    "tune_stats = pd.DataFrame({\n",
    "    'Tune Length': tune_lens,\n",
    "    'Tune Index': range(len(tune_lens))\n",
    "})\n",
    "\n",
    "# Display basic statistics in a DataFrame\n",
    "display(tune_stats.describe())\n",
    "\n",
    "# Plot a histogram of tune lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(tune_stats['Tune Length'], kde=True, bins=30, color='skyblue')\n",
    "plt.title(\"Distribution of Tune Lengths\", fontsize=16)\n",
    "plt.xlabel(\"Tune Length\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Plot a box plot for tune lengths\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=tune_stats['Tune Length'], color='lightgreen')\n",
    "plt.title(\"Spread of Tune Lengths\", fontsize=16)\n",
    "plt.xlabel(\"Tune Length\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Token frequency analysis\n",
    "token_freq = pd.Series(data=0, index=idx2token)\n",
    "for tune in tunes:\n",
    "    for idx in tune:\n",
    "        token_freq[idx2token[idx]] += 1\n",
    "\n",
    "# Display top 10 tokens in a DataFrame\n",
    "top_tokens = token_freq.sort_values(ascending=False).head(30)\n",
    "display(pd.DataFrame(top_tokens, columns=['Frequency']))\n",
    "\n",
    "# Bar chart of top 10 tokens\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_tokens.plot(kind='bar', color='orange')\n",
    "plt.title(\"Top 10 Tokens by Frequency\", fontsize=16)\n",
    "plt.xlabel(\"Token\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a84a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tune_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbb897",
   "metadata": {},
   "source": [
    "### Shows what the output looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f484072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your .pkl file\n",
    "pkl_file_path = 'metadata/folkrnn_v2.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pkl_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "303375f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Path to the input text file\n",
    "input_file = \"DutchFolkTunes\\dataset.txt\"  # Replace with your file path\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(input_file, \"r\") as file:\n",
    "    input_string = file.read()\n",
    "\n",
    "\n",
    "# Regular expression to find patterns like [M ... ], [K ... ], or [L ... ]\n",
    "pattern = r\"(\\[M.*?\\])|(\\[K.*?\\])|(\\[L.*?\\])\"\n",
    "\n",
    "# Add a newline before the matched patterns\n",
    "modified_string = re.sub(pattern, lambda m: \n",
    "    '\\n' + (m.group(2) + '\\n' if m.group(2) else m.group(1) if m.group(1) else m.group(3)), \n",
    "    input_string)\n",
    "\n",
    "modified_string = re.sub(pattern, lambda m: (\n",
    "    '\\n' + (m.group(2) + '\\n' if m.group(2) else  # [K ... ]: add newline after\n",
    "    ('\\n' + m.group(3) if m.group(3) else  # [L ... ]: add newline before\n",
    "    m.group(1)))  # [M ... ]: no changes\n",
    "), input_string)\n",
    "\n",
    "\n",
    "# Path to the output text file\n",
    "output_file = \"DutchFolkTunes\\output.txt\"  # Replace with your desired output file path\n",
    "\n",
    "# Write the modified content to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(modified_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2680ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "\n",
    "# Function to process lines\n",
    "def process_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    processed_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Use a regular expression to find two consecutive numbers (e.g., \"23\") and remove everything after\n",
    "        match = re.search(r'\\d{2,}', line)  # Matches any sequence of 2 or more digits\n",
    "        if match:\n",
    "            line = line[:match.start()]  # Keep only content before the match\n",
    "        processed_lines.append(line.strip())\n",
    "    \n",
    "    # Save the processed lines to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for processed_line in processed_lines:\n",
    "            file.write(processed_line + '\\n')\n",
    "    \n",
    "    #print(f\"Processed lines saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_filename = \"DutchFolkTunes\\output.txt\"   # Replace with your input file name\n",
    "output_filename = \"DutchFolkTunes\\Finaloutput.txt\" # Replace with your desired output file name\n",
    "process_lines(input_filename, output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file = \"DutchFolkTunes\\output.txt\"  # Replace with your input text file\n",
    "output_file = r\"DutchFolkTunes\\testoutput.txt\"  # Replace with your desired output path\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Open the input file and process the lines\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a list to store the filtered lines\n",
    "filtered_lines = []\n",
    "\n",
    "# Loop through the lines and apply the condition\n",
    "for line in lines:\n",
    "    # Check if the line starts with [M and does not end with ]\n",
    "    if not (line.startswith(\"[M\") and not line.rstrip().endswith(\"]\")):\n",
    "        filtered_lines.append(line)\n",
    "\n",
    "# Write the filtered lines to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.writelines(filtered_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dd6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file = r\"DutchFolkTunes\\testoutput.txt\"  # Replace with your input text file\n",
    "output_file = r\"DutchFolkTunes\\finalv2.txt\"  # Replace with your desired output path\n",
    "\n",
    "# Open the input file and process the lines\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a list to store valid samples\n",
    "valid_samples = []\n",
    "\n",
    "# Define the expected line structure\n",
    "expected_format = [\n",
    "    lambda line: line.startswith(\"[L\") and line.endswith(\"]\\n\"),  # First line\n",
    "    lambda line: line.startswith(\"[M\") and line.endswith(\"]\\n\"),  # Second line\n",
    "    lambda line: line.startswith(\"[K\") and line.endswith(\"]\\n\"),  # Third line\n",
    "    lambda line: True,  # Fourth line (any string)\n",
    "    lambda line: line.strip() == \"\",  # Fifth line (empty line)\n",
    "]\n",
    "\n",
    "# Process the lines in groups of 5\n",
    "sample = []\n",
    "for line in lines:\n",
    "    line = line.replace(\"[\", \"\").replace(\"]\", \"\")  # Remove all '[' and ']'\n",
    "    sample.append(line)\n",
    "    if len(sample) == 5:  # Check a complete sample\n",
    "        if all(check_fn(sample[i]) for i, check_fn in enumerate(expected_format)):\n",
    "            valid_samples.extend(sample)  # Add valid sample to the list\n",
    "        sample = []  # Reset for the next sample\n",
    "\n",
    "# Write the valid samples to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.writelines(valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6ed45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file = r\"DutchFolkTunes\\OriginalDataset.txt\"  # Replace with your input text file\n",
    "output_file = r\"DutchFolkTunes\\OriginalDatasetNoBrackets.txt\"  # Replace with your desired output text file\n",
    "\n",
    "# Open the input file and process the lines\n",
    "with open(input_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a list to store valid samples\n",
    "valid_samples = []\n",
    "\n",
    "# Process the lines in groups of 5\n",
    "sample = []\n",
    "for line in lines:\n",
    "    line = line.replace(\"[\", \"\").replace(\"]\", \"\")  # Remove all '[' and ']'\n",
    "    sample.append(line)\n",
    "    if len(sample) == 5:  # Process a complete sample\n",
    "        valid_samples.extend(sample)  # Add sample to the list\n",
    "        sample = []  # Reset for the next sample\n",
    "\n",
    "# Write the valid samples to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.writelines(valid_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0fae498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\x80\\x02}q\\x01(U\\ttoken2idxq\\x02}q\\x03(U\\x02d'q\\x04K\\x00U\\x05M:3/8q\\x05K^U\\x02=eq\\x06K\\x01U\\x02=dq\\x07K\\x02U\\x02=gq\\x08K\\x03U\\x02=fq\\tK\\x04U\\x02=aq\\r\\nK\\x05U\\x02=cq\\x0bK\\x06U\\x02=bq\\x0cK\\x07U\"\n",
      "b\"\\x80\\x02}q\\x00(U\\ttoken2idxq\\x01}q\\x02(U\\x02d'q\\x03K\\x00U\\x03=A,q\\x04K\\x01U\\x03^c'q\\x05K\\x02U\\x02=eq\\x06K\\x03U\\x02=dq\\x07K\\x04U\\x02=gq\\x08K\\x05U\\x02=fq\\tK\\x06U\\x02=aq\\nK\\x07U\\x02=cq\\x0bK\\x08U\\x02=\"\n"
     ]
    }
   ],
   "source": [
    "with open('.\\\\metadata\\\\config5--20250109-102849.pkl', 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    print(raw_data[:100])  # View the first 100 bytes\n",
    "    \n",
    "with open('.\\\\metadata\\\\folkrnn_v2.pkl', 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    print(raw_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8bfad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "\n",
    "# Define a function to clean the text file\n",
    "def clean_text_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    for i in range(len(lines)):\n",
    "        # Check if the current line is a [K line\n",
    "        if lines[i].startswith('[K:'):\n",
    "            # Ensure the previous line is an [M line\n",
    "            if i > 0 and lines[i - 1].startswith('[M:'):\n",
    "                cleaned_lines.append(lines[i])  # Keep the [K line\n",
    "                cleaned_lines.append(lines[i + 1])  # Keep the corresponding string line\n",
    "        # Otherwise, keep non-[K lines\n",
    "        elif not (i > 0 and lines[i - 1].startswith('[K:') and lines[i].strip()):\n",
    "            cleaned_lines.append(lines[i])\n",
    "\n",
    "    # Write the cleaned content back to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_file = './DutchFolkTunes/noExtraM.txt'  # Replace with the path to your input file\n",
    "output_file = './DutchFolkTunes/noExtraK.txt'  # Replace with the desired path for the output file\n",
    "\n",
    "# Call the function to clean the file\n",
    "clean_text_file(input_file, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2462f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import re\n",
    "\n",
    "# Define a function to validate and clean the text file\n",
    "def validate_and_clean_text_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "\n",
    "        # First condition: Remove [L lines that don't end with ] and the next 3 lines\n",
    "        if line.startswith('L') and not line.strip().endswith(']'):\n",
    "            i += 1  # Skip the next 3 lines as well\n",
    "            continue\n",
    "\n",
    "        # Keep the current line if all conditions are satisfied\n",
    "        cleaned_lines.append(line)\n",
    "        i += 1\n",
    "\n",
    "    # Write the cleaned content back to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "        \n",
    "    # Specify the input and output file paths\n",
    "input_file = './DutchFolkTunes/OriginalDatasetNoBrackets.txt'  # Replace with the path to your input file\n",
    "output_file = './DutchFolkTunes/OriginalDatasetNoL.txt'  # Replace with the desired path for the output file\n",
    "# Call the function to clean the file\n",
    "validate_and_clean_text_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d60416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_c_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    cleaned_lines = []\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "\n",
    "        # Check if the line starts with 'c'\n",
    "        if line.startswith('c'):\n",
    "            # Ensure the previous line contains '[K'\n",
    "            if i == 0 or not lines[i - 1].startswith('[K'):\n",
    "                continue  # Skip the 'c' line if the condition is not met\n",
    "\n",
    "        # Add the line to the cleaned output\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    # Write the cleaned content back to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "\n",
    "# Specify the input and output file paths\n",
    "input_file = './DutchFolkTunes/filteredv2.txt'  # Replace with the path to your input file\n",
    "output_file = './DutchFolkTunes/filteredv3.txt'  # Replace with the desired path for the output file\n",
    "# Call the function to clean the file\n",
    "validate_c_lines(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b2fde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_20000_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            if i >= 20000:\n",
    "                break\n",
    "            outfile.write(line)\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file = './data/data_v2'  # Replace with the path to your input file\n",
    "output_file = './data/data_v2Small'  # Replace with the desired output file path\n",
    "\n",
    "# Extract the first 20000 lines\n",
    "extract_first_20000_lines(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
