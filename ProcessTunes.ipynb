{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc14cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from itertools import izip  # For Python 2 compatibility, use `zip` if on Python 3\n",
    "import os\n",
    "\n",
    "# Configurations (modify as needed)\n",
    "class Config:\n",
    "    validation_fraction = 0.2  # Fraction of data used for validation\n",
    "    batch_size = 32  # Batch size\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Define data path\n",
    "data_path = 'data/data_v2'\n",
    "assert os.path.exists(data_path), \"Data path does not exist!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc710d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data from the specified path\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Split the data into tokens and initialize the token set\n",
    "tokens_set = set(data.split())\n",
    "start_symbol, end_symbol = '<s>', '</s>'\n",
    "tokens_set.update({start_symbol, end_symbol})\n",
    "\n",
    "# Create vocabulary mappings\n",
    "idx2token = list(tokens_set)\n",
    "vocab_size = len(idx2token)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "token2idx = dict(izip(idx2token, range(vocab_size)))  # Use zip for Python 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the tunes and tokenize them\n",
    "tunes = data.split('\\n\\n')\n",
    "del data  # Free up memory\n",
    "\n",
    "tunes = [\n",
    "    [token2idx[c] for c in [start_symbol] + t.split() + [end_symbol]]\n",
    "    for t in tunes\n",
    "]\n",
    "\n",
    "# Sort tunes by length (longest first)\n",
    "tunes.sort(key=lambda x: len(x), reverse=True)\n",
    "ntunes = len(tunes)\n",
    "print('Number of tunes:', ntunes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f0b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tunes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa70359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate tune lengths\n",
    "tune_lens = np.array([len(t) for t in tunes])\n",
    "max_len = max(tune_lens)\n",
    "print('Max tune length:', max_len)\n",
    "\n",
    "# Calculate the number of validation tunes\n",
    "nvalid_tunes = ntunes * config.validation_fraction\n",
    "nvalid_tunes = config.batch_size * max(\n",
    "    1, int(round(nvalid_tunes / float(config.batch_size)))\n",
    ")  # Round to a multiple of batch_size\n",
    "print('Number of validation tunes:', nvalid_tunes)\n",
    "\n",
    "# Split into training and validation sets\n",
    "rng = np.random.RandomState(42)  # Fixed seed for reproducibility\n",
    "valid_idxs = rng.choice(np.arange(ntunes), int(nvalid_tunes), replace=False)\n",
    "\n",
    "# Create validation and training datasets\n",
    "valid_tunes = [tunes[i] for i in valid_idxs]\n",
    "train_tunes = [tunes[i] for i in range(ntunes) if i not in valid_idxs]\n",
    "\n",
    "print('Training tunes:', len(train_tunes))\n",
    "print('Validation tunes:', len(valid_tunes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'DutchFolkTunes/dataset.txt'\n",
    "assert os.path.exists(data_path), \"Data path does not exist!\"\n",
    "\n",
    "\n",
    "# Load data from the specified path\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Split the data into tokens and initialize the token set\n",
    "tokens_set = set(data.split())\n",
    "start_symbol, end_symbol = '<s>', '</s>'\n",
    "tokens_set.update({start_symbol, end_symbol})\n",
    "\n",
    "# Create vocabulary mappings\n",
    "idx2token = list(tokens_set)\n",
    "vocab_size = len(idx2token)\n",
    "print('Vocabulary size:', vocab_size)\n",
    "token2idx = dict(izip(idx2token, range(vocab_size)))  # Use zip for Python 3\n",
    "\n",
    "# Process the tunes and tokenize them\n",
    "tunes = data.split('\\n\\n')\n",
    "del data  # Free up memory\n",
    "\n",
    "tunes = [\n",
    "    [token2idx[c] for c in [start_symbol] + t.split() + [end_symbol]]\n",
    "    for t in tunes\n",
    "]\n",
    "\n",
    "# Sort tunes by length (longest first)\n",
    "tunes.sort(key=lambda x: len(x), reverse=True)\n",
    "ntunes = len(tunes)\n",
    "print('Number of tunes:', ntunes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a07236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tune lengths\n",
    "tune_lens = np.array([len(t) for t in tunes])\n",
    "max_len = max(tune_lens)\n",
    "print('Max tune length:', max_len)\n",
    "\n",
    "# Calculate the number of validation tunes\n",
    "nvalid_tunes = ntunes * config.validation_fraction\n",
    "nvalid_tunes = config.batch_size * max(\n",
    "    1, int(round(nvalid_tunes / float(config.batch_size)))\n",
    ")  # Round to a multiple of batch_size\n",
    "print('Number of validation tunes:', nvalid_tunes)\n",
    "\n",
    "# Split into training and validation sets\n",
    "rng = np.random.RandomState(42)  # Fixed seed for reproducibility\n",
    "valid_idxs = rng.choice(np.arange(ntunes), int(nvalid_tunes), replace=False)\n",
    "\n",
    "# Create validation and training datasets\n",
    "valid_tunes = [tunes[i] for i in valid_idxs]\n",
    "train_tunes = [tunes[i] for i in range(ntunes) if i not in valid_idxs]\n",
    "\n",
    "print('Training tunes:', len(train_tunes))\n",
    "print('Validation tunes:', len(valid_tunes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set up plot styles\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Prepare a pandas DataFrame for tune lengths\n",
    "tune_stats = pd.DataFrame({\n",
    "    'Tune Length': tune_lens,\n",
    "    'Tune Index': range(len(tune_lens))\n",
    "})\n",
    "\n",
    "# Display basic statistics in a DataFrame\n",
    "display(tune_stats.describe())\n",
    "\n",
    "# Plot a histogram of tune lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(tune_stats['Tune Length'], kde=True, bins=30, color='skyblue')\n",
    "plt.title(\"Distribution of Tune Lengths\", fontsize=16)\n",
    "plt.xlabel(\"Tune Length\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Plot a box plot for tune lengths\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=tune_stats['Tune Length'], color='lightgreen')\n",
    "plt.title(\"Spread of Tune Lengths\", fontsize=16)\n",
    "plt.xlabel(\"Tune Length\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Token frequency analysis\n",
    "token_freq = pd.Series(data=0, index=idx2token)\n",
    "for tune in tunes:\n",
    "    for idx in tune:\n",
    "        token_freq[idx2token[idx]] += 1\n",
    "\n",
    "# Display top 10 tokens in a DataFrame\n",
    "top_tokens = token_freq.sort_values(ascending=False).head(30)\n",
    "display(pd.DataFrame(top_tokens, columns=['Frequency']))\n",
    "\n",
    "# Bar chart of top 10 tokens\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_tokens.plot(kind='bar', color='orange')\n",
    "plt.title(\"Top 10 Tokens by Frequency\", fontsize=16)\n",
    "plt.xlabel(\"Token\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a84a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tune_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbb897",
   "metadata": {},
   "source": [
    "### Shows what the output looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f484072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your .pkl file\n",
    "pkl_file_path = 'metadata/folkrnn_v2.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pkl_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "303375f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Path to the input text file\n",
    "input_file = \"DutchFolkTunes\\dataset.txt\"  # Replace with your file path\n",
    "\n",
    "# Read the content of the input file\n",
    "with open(input_file, \"r\") as file:\n",
    "    input_string = file.read()\n",
    "\n",
    "\n",
    "# Regular expression to find patterns like [M ... ], [K ... ], or [L ... ]\n",
    "pattern = r\"(\\[M.*?\\])|(\\[K.*?\\])|(\\[L.*?\\])\"\n",
    "\n",
    "# Add a newline before the matched patterns\n",
    "modified_string = re.sub(pattern, lambda m: \n",
    "    '\\n' + (m.group(2) + '\\n' if m.group(2) else m.group(1) if m.group(1) else m.group(3)), \n",
    "    input_string)\n",
    "\n",
    "modified_string = re.sub(pattern, lambda m: (\n",
    "    '\\n' + (m.group(2) + '\\n' if m.group(2) else  # [K ... ]: add newline after\n",
    "    ('\\n' + m.group(3) if m.group(3) else  # [L ... ]: add newline before\n",
    "    m.group(1)))  # [M ... ]: no changes\n",
    "), input_string)\n",
    "\n",
    "\n",
    "# Path to the output text file\n",
    "output_file = \"DutchFolkTunes\\output.txt\"  # Replace with your desired output file path\n",
    "\n",
    "# Write the modified content to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(modified_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2680ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "\n",
    "# Function to process lines\n",
    "def process_lines(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    processed_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Use a regular expression to find two consecutive numbers (e.g., \"23\") and remove everything after\n",
    "        match = re.search(r'\\d{2,}', line)  # Matches any sequence of 2 or more digits\n",
    "        if match:\n",
    "            line = line[:match.start()]  # Keep only content before the match\n",
    "        processed_lines.append(line.strip())\n",
    "    \n",
    "    # Save the processed lines to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        for processed_line in processed_lines:\n",
    "            file.write(processed_line + '\\n')\n",
    "    \n",
    "    #print(f\"Processed lines saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_filename = \"DutchFolkTunes\\output.txt\"   # Replace with your input file name\n",
    "output_filename = \"DutchFolkTunes\\Finaloutput.txt\" # Replace with your desired output file name\n",
    "process_lines(input_filename, output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and output file paths\n",
    "input_file = \"DutchFolkTunes\\output.txt\"  # Replace with your input text file\n",
    "output_file = \"DutchFolkTunes\\testoutput.txt\"  # Replace with your desired output text file\n",
    "\n",
    "# Open the input file and process the lines\n",
    "with open(input_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a list to store the filtered lines\n",
    "filtered_lines = []\n",
    "\n",
    "# Loop through the lines and apply the condition\n",
    "for line in lines:\n",
    "    # Check if the line starts with [M and does not end with ]\n",
    "    if not (line.startswith(\"[M\") and not line.rstrip().endswith(\"]\")):\n",
    "        filtered_lines.append(line)\n",
    "\n",
    "# Write the filtered lines to the output file\n",
    "with open(output_file, 'w') as file:\n",
    "    file.writelines(filtered_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
